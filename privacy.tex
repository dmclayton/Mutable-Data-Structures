
The semantic security of the immutable case cannot be easily extended to the mutable case. If the same experiment is used, but with the adversary additionally given access to an $\UPO$ oracle, the adversary can often easily learn the composition of the original set using this oracle. For example, with a standard Bloom filter, the adversary can attempt to insert an element of its choice. The representation will remain the same if and only if that element was already in the filter.

There is also the question of whether there is a natural analog to one-wayness for mutable data structures. Even if the adversary is not allowed to choose the underlying data object and must attempt to guess its contents from its public representation, in the mutable case we must assume the adversary can see the representation change over time as updates occur. We assume there is no way to know in advance which updates will be carried out, and hence no known distribution over $\mathcal{U}$. Therefore, to be cautious, we should let the adversary choose the updates. If the adversary can choose and apply any update it likes, the security notion would of course be impossible to achieve (the adversary will know what elements were added by the updates it chose to make). An alternative is to have the two experiments. In each, the adversary chooses two updates with identical leakage, and the oracle either consistently applies the first (in experiment 0) or consistently applies the second (in experiment 1). But this again leads to problems where the adversary can observe whether the representation has changed in order to determine which elements have previously been added to it.

In short, it is extremely unclear how to extend privacy notions to the mutable case without making the adversary so powerful that they can easily discern the contents of the data structures in question.

