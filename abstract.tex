Probabilistic data structures use space-efficient representations of data in order to
(approximately) respond to queries about the data. 
Traditionally, these structures are accompanied by probabilistic bounds on
query-response errors. These bounds implicitly assume benign attack
models, in which the data and the queries are inputs are chosen
non-adaptively, and independent of the randomness used to
construct the representation. Yet probabilistic data structures are
increasingly used in settings where these assumptions may be violated.

This work provides a provable security treatment of probabilistic data
structures in adversarial environments. We give a syntax that captures a wide
variety of in-use structures, and our security notions support
development of error bounds in the presence of powerful attacks.
%
Concretely, we examine the widely used Bloom filter, counting (Bloom)
filter, and count-min sketch data structures.  For the traditional
version of these, our security findings are largely negative; however,
we show that simple embellishments (e.g., using salts, or secret keys)
yields structures that provide provable security, and with little overhead.


\ignore{
  This work initiates the study of abstract data structures from a cryptographic
  perspective.  We first establish a precise syntax that captures a broad
  class of real-world data structures.  We then treat the
  \emph{correctness} and \emph{privacy} of data structures
  as security properties, and establish formal security notions for
  each.  Loosely, our notion of correctness captures an (adaptive) adversary's ability to cause
  a data structure to err in the course of responding to a set of supported
  queries, and our two privacy notions neatly capture what a data structure leaks about
  the data it represents.

  We use our formalisms to explore the security of the widely used
  Bloom filter~\cite{bloom1970space} and some important variants.
  %
  We find, for example, that the security of Bloom filters depends
  crucially on whether or not the underlying hash functions are known
  by the adversary prior to the filter being constructed.
  %
  We also study a real-world mechanism for privacy-preserving record
  linkage (over hospital databases).  Our notions provide a crisp view of the
  (in)security of this Bloom-filter-based mechanism.
  %
  To demonstrate the broader applicability of our definitions, we move
  from data structures supporting set-membership queries (only) to
  dictionary data structures.  Concretely, we analyze the ``Bloomier
  filter''~\cite{chazelle2004bloomier}, which provides a compact
  representation of a key/value store.
}
