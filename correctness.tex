\input{correctness-experiment}

%We will measure error with the help of an error function $d: \mathcal{R}^2 \to [0,\infty)$, which may depend on the application rather than being given by the specification of a data structure alone. The value $d(x,y)$ represents the `badness' of getting an erroneous result of $x$ from $\Qry$ when $y$ should actually have been returned. In general we require $d(x,x) = 0$, but otherwise place no restrictions on what the error function might look like.

We define two adversarial notions of correctness given by a pair of related experiments for a mutable data structure $\struct$, error function $d: \mathcal{R}^2 \to [0,\infty)$, and error capacity $r$. The vales $d(x,y)$ of the error function represent the `badness' of getting an erroneous result of $x$ from $\Qry$ when $y$ should actually have been returned. In general we require $d(x,x) = 0$ for all $x$, but otherwise place no restrictions on what the error function might look like.

The two correctness notions correspond to cases where the representations of the true data are public ($\errep$) and where they are private ($\erreps$). We will describe the former and then give a brief explanation of how the latter differs, as the two are closely related to each other.

While many potential errors may exist for a given representation of a set, in the form of queries $\qry$ that would return an inaccurate answer when sent to $\QRYO$, we want an experiment that forces the adversary to actually find specific erroneous queries. In particular, we only give the adersary credit when they actually make a $\QRYO$ call that produces an error.

Both experiments aim to capture the total weight of the errors caused by the adversary, at any point in time, with respect to the current data objects $\col_i$ and their representations $\pub_i$.  Because we consider mutable data objects and representations, the notion of ``current'' is defined by calls to the $\REPO$ and $\UPO$ oracles.  Specifically, for each~$\col_i$, both experiments maintain a set~$\setC_i$ that is initially set to empty (when~$\col_i$ is first assigned via a~$\REPO$-query), and it is reset to empty whenever~$\col_i$ is updated via an $\UPO$-query.  This is capturing the fact that applying a non-empty update function~$\up$ to~$\col_i$ produces a new data object.

To track errors, both experiments maintain an array $\err_i[]$ for every data object~$\col_i$ that has been defined.   Initially, $\err_i[]$ is implicitly assigned the value of~$\undefn$ at every index.  For purposes of value comparison, we adopt the convention that $\undefn < n$ for all $n \in \mathbb{R}$.
%
Now, the array~$\err_i$ is indexed by query functions~$\qry$, and the value of $\err_i[\qry]$ is the ``weight'' of the error caused by~$\qry$, with respect to the \emph{current} data object~$\col_i$ and \emph{current} representation~$\pub_i$ (of~$\col_i$).  
%
The value of~$\err_i[\qry]$ is updated within the $\QRYO$- and $\UPO$-oracles, but observe that $\err_i[\qry] = \undefn$ until $(i,\qry)$ is queried to the $\QRYO$-oracle.  Intuitively, a representation~$\pub_i$ of data object~$\col_i$ cannot surface errors until it is queried.

When~$\QRYO(i,\qry)$ executes, the value in $\err_i[\qry]$ is overwritten iff the error caused by~$\qry$ is larger than the existing value of $\err_i[\qry]$.  The first time $(i,\qry)$ is queried to~$\QRYO$ this is guaranteed, since the minimum possible value of $d$ is 0.  Since the set $\setC_i$ is used to prevent (WLOG) the adversary from repeating a query~$\QRYO(i,\qry)$ for a given~$\col_i$, increases to the value of $\err_i[\qry]$ may only be made ``across'' updates to~$\col_i$.  This may seem to be overly conservative, as an error-heavy~$\col_i$ may become less so after an update.  But we account for this within the $\UPO$-oracle.
In particular, calls to the $\UPO$-oracle may only \emph{decrease} the value of~$\err_i[\qry]$.  

When a query $\UPO(i,\up)$ is made, the oracle first updates the data object~$\col_i$ and its corresponding representation.  The set~$\setC_i$ is reset to empty, because the data object~$\col_i$ is ``new'' again.
%
Now, for each defined value~$\err_i[\qry]$, we reevaluate the error that \emph{would} be caused by the previously asked~$\qry$ w.r.t. the newly updated $\col_i$ and $\pub_i$.  If the existing value of $\err_i[\qry]$ is larger than the error that~$\qry$ would cause to w.r.t. the newly updated~$\col_i$ and $\pub_i$, then we overwrite $\err_i[\qry]$ with the smaller value.  Doing so insures that the array~$\err_i$ does not overcredit the attacker for errors against the current data object and representation.

For a concrete example of why these choices are necessary, consider a representation~$\pub$ of the set~$\col = \{1,2,3\}$ in some structure that supports set membership queries. Suppose an adversary learns that~$4$ is a false-positive value for $\pub$. If the adversary later uses an $\UPO$ query to add~$4$ to~$\col$, this should no longer count as a false positive. Our definition ensures that these known false positives are checked for and no longer counted if added to the set.

The private-representation case differs from the public-representation case only in that the $\REPO$ and $\UPO$ oracles do not reveal the representation to the adversary. This models the case where the data structure is stored privately, where the adversary can ask queries but not see the full representation. To model the possibility that information about a representation is eventually leaked, we also give the adversary a $\REVO$ oracle that reveals a given representation. However, to prevent this from being trivially equivalent to the public-representation case we do not allow the adversary to win by finding errors in a representation which has been revealed using $\REVO$. However, security in the private-representation case is implied by security in the public-representation case, since any attack in the private-representation setting also works in the public-representation setting.

Given the experiments defined here, we define the advantage of an adversary $\advA$ as the probability it succeeds at the experiment, i.e. $\Adv{\errep}_{\struct,r}(\advA) = \Prob{\Exp{\errep}_{\struct,r}(\advA) = 1}$ in the public-representation case and $\Adv{\erreps}_{\struct,r}(\advA) = \Prob{\Exp{\erreps}_{\struct,r}(\advA) = 1}$ in the private-representation case. For constants $t$, $q_R$, $q_T$, $q_U$, $q_H$, we define $\Adv{\errep}_{\struct,r}(t,q_R,q_T,q_U,q_H)$ to be the maximum advantage attained by an adversary running in $t$ time steps and making $q_R$ calls to $\REPO$, $q_T$ calls to $\QRYO$, $q_U$ calls to $\UPO$, and $q_H$ calls to a random oracle. The advantage is defined analagously in the private-representation setting.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Generic results}
First, we note that any structure which is insecure in the immutable case is also insecure in the mutable case. Any adversary in the immutable case is identical to a corresponding adversary in the mutable case which simply never makes use of the $\UPO$ oracle. From this we know that standard (unsalted, unkeyed) Bloom filters cannot ensure correctness in the mutable case. \tsnote{This is supported by a result that doesn't appear here.  We should port over relevant results from the previous draft paper.}


\heading{Keyless structures.}

In a keyless structure, we assume all details of the algorithm used are known beforehand by the adversary, except any which might be generated `on the fly' as representations are created and modified. For example, many of these structures will assume the use of a random salt which is picked at the time the representation is created. A structure with neither randomization nor a private key is usually vulnerable to pre-computation and offline attacks, where the adversary can search for errors to produce without having to interact with the structure itself.

In many cases, it is easier to reason about an adversary which only has the chance to create and manipulate a single representation, rather than being able to call a $\REPO$ oracle as many times as it likes. Fortunately, in the case of keyless structures we can show that the adversary's advantage in a single-representation case is bounded above by a multiple of the advantage in the general case. We use $\errep1$ and $\erreps1$ to denote the public-representation and private-representation experiments where the adversary makes a single $\REPO$ query. In writing the advantage for these games we omit the $q_R$ parameter since it is fixed at 1.

%There are two equivalent ways of defining the $\errep1$ experiment. First, we may define it as a modified version of $\errep$ in which the adversary is constrained to make no more than one call to $\REPO$. We may equivalently define it as a two-stage adversary in the experiment below.

%\input{correctness-experiment-1}

Note that in the $\erreps1$ scenario we need not provide the adversary with a $\REVO$ oracle. If the adversary uses only a single representation, may assume without loss of generality that they make no call to $\REVO$, since doing so would prevent the adversary from having any possibility of winning. Since the case of a single $\REPO$ query is considerably simpler to handle, the first step in each of our proofs will be to reduce $\errep$ and $\erreps$ to $\errep1$ and $\erreps1$ respectively.% In addition to this, we wish to move from actual hash functions to true random functions. Using the following lemmas, we may reduce the case of $\errep$ for any structure using a salted hash to the case of $\errep1$ using a true random function, and we may reduce $\erreps$ for a structure using a secret-keyed hash to the case of $\erreps1$ using a true random function.

\begin{lemma}[\errep1 and \erreps1 imply \errep and \erreps for keyless structures]\label{lemma:errep}
  Let $\struct = (\Rep, \Qry, \Up)$ be a data structure with key
  space $\{\emptystr\}$. For every $t, q_R, q_T, q_U, q_H, r\geq 0$, it holds that
  \[
    \Adv{\errep}_{\struct,r}(t, q_R, q_T, q_U, q_H) \leq
    q_R\cdot\Adv{\errep1}_{\struct,r}(O(f(t)), q_T, q_U, q_H) \,,
  \]
  where $f(t) = t + (q_R-1)\ticks(\Rep,t) + q_T\ticks(\Qry,t) + q_U\ticks(\Up,t)$.
\end{lemma}

\begin{proof}For a fixed $r \ge 0$, let $\advA$ be an $\errep$ or $\erreps$ adversary which runs in $t$ time steps and makes $q_R$ $\REPO$ queries, $q_T$ $\QRYO$ queries, $q_U$ $\UPO$ queries, and $q_H$ RO queries. We construct an adversary $B$ for $\errep1$ or $\erreps1$, respectively, as follows.

First, $\advB$ initializes a counter $ct \gets 0$ and a set $\setC \gets \emptyset$, and samples $q \getsr [q_R]$. Next $\advB$ executes $\advA$, simulating the answers to its oracle queries as follows. When $\advA$ asks the query $\REPO(\col)$, $\advB$ sets $ct \gets ct + 1$ and stores $\col_{ct} \gets \col$. Then, if $ct = q$, $B$ forwards $\col$ to its own $\REPO$ oracle, returning the resulting value ($\pub$ in the public-representation case, or $\top$ in the private-representation case) to $\advA$. Otherwise, $\advB$ computes $\pub_{ct} \getsr \Rep(\col)$ and returns either $\pub_{ct}$ or $\top$. When $\advA$ asks for the query $\QRYO(i,\qry)$, $\advB$ first checks if $(i,\qry) \in \setC$ and returns $\bot$ if this condition holds. Otherwise $\advB$ forwards $(i,\qry)$ to its $\QRYO$ oracle and returns $a$ if $i = q$, and reutrns $\Qry(\pub_i,\qry)$ otherwise. Similarly, when $\advA$ makes an $\UPO(i,\up)$ query, $\advB$ forwards $(i,\up)$ to its $\UPO$ oracle if $i = q$ and evaluates $\Up(\pub_i,\up)$ otherwise. Finally, queries from $\advA$ to its RO are simply forwarded to $\advB$'s RO. When $\advA$ halts and outputs $j$, $\advB$ does the same.

If $j = q$, then $B$ wins if $A$ does, since all queries from $A$ to $\pub_j$ were forwarded to $B$'s $\QRYO$ oracle. Given that $q$ is sampled uniformly from the range $[q_R]$, it follows that

$$\Adv{\errep}_{\struct,r}(t, q_R, q_T, q_U, q_H) \leq q_R\cdot\Adv{\errep1}_{\struct,r}(O(f(t)), q_T, q_H).$$

Note that $B$ makes at most $q_T$ queries to $\QRYO$ and $q_H$ queries to its RO. Since $A$ runs in $t$ time steps and writing a bit takes 1 time step, the input length to any $\Rep$, $\Qry$, or $\Up$ evaluated by $B$ is at most $t$ bits. Hence, adversary $B$ runs in time $O(t+(q_R-1)\ticks(\Rep,t)+q_T\ticks(\Qry,t)+q_U\ticks(\Up,t))$.\missingqed
\end{proof}

\heading{Keyed structures.}

As in the keyless case, we can reduce the case of $\erreps$ for a secretly-keyed hash to the case of $\erreps1$ using a true random function. Though the proof is different, we achieve a similar bound as in the unkeyed private-representation case. Despite the similar-looking bounds, the secret-keyed case is preferable in practice because the $q_R$ $\REPO$ queries are `online' while the $q_H$ $\HASHO$ queries are `offline', limited only by the computational capabilities of the adversary.

\begin{lemma}[\errep1 with random functions implies \errep with keyed hashing]\label{lemma:keytorand}
  Let $\struct = (\Rep, \Qry, \Up)$ be a data structure with key space $\mathcal{K}$ and salt space $\bits^\lambda$, and let $\struct'$ be the same structure using true random functions in place of salted and keyed hash functions. For every $t, q_R, q_T, q_U, q_H, r \geq 0$, it holds that
  \[
    \Adv{\errep1}_{\struct,r}(t, q_R, q_T, q_U, q_H) \leq \frac{q_R^2}{2^\lambda} + q_R \cdot \Adv{\errep1}_{\struct',r}(t, q_R, q_T, q_U, q_H)
  \]
\end{lemma}

\begin{proof}
In each of the structures considered here, we model the use of a secretly keyed hash function with the use of a pseudorandom function $F_K$. Let $\game_0$ be the $\errep$ game on this structure. Our first step is to move to a game $\game_1$ where the pseudorandom function $F_K$ is replaced by a true random function $\Rnd$ which is lazily evaluated as necessary when $\REPO$, $\QRYO$, and $\UPO$ are called. By a conditioning argument, the advantage of the adversary is given by $\Adv{\errep}_{\struct,r}(\advA) = \Adv{\prf}_F(\advB) + \Prob{\game_1(\advA)=1}$.

Consider another game $\game_2$ that ensures the salts do not repeat, by choosing $\salt$ exclusively from salts which have not been previously used. The game is identical to $\game_1$ until a salt repeats, which by the birthday bound occurs with probability $q_R^2/2^\lambda$. Therefore $\Adv{\errep}_{\struct,r}(\advA) = \Adv{\prf}_F(\advB) + q_R^2/2^\lambda + \Prob{\game_2(A) = 1}$.

Next, we revise the game to $\game_3$ where the adversary gets credit for queries $\QRYO(i,\qry)$ which are false positives for any $\pub_j$, regardless of the actual argument $i$ given to $\QRYO$. Since this can only benefit the adversary, $\Adv{\errep}_{\struct,r}(\advA) \le \Adv{\prf}_F(\advB) + q_R^2/2^\lambda + \Prob{\game_3(A) = 1}$.

However, because each representation makes use of a random function for determining the value of all representations, updates, and queries, the probability of a previously unqueried element producing an error in one representation is independent of its probability of producing an error in the other representations. When we move to the final game $\game_4$ where the adversary is only allowed to call $\REPO$ once, the adversary's advantage will then decrease by a factor of at most $q_R$. This gives us the final result:

$$\Adv{\errep}_{\struct,r}(\advA) \le \Adv{\prf}_F(\advB) + \frac{q_R^2}{2^\lambda} + q_R \cdot \Prob{\game_4(A) = 1}$$\missingqed
\end{proof}

\heading{Invertible structures.}

Several structures are designed to implement both insertion and deletion operates. This allows the adversary a great deal of variety in the updates it can perform during the security experiment. For a more general notion, we define an \textit{invertible} structure as one where, for any initial representation $\pub$ and any other representation $\pub' = \Up_K(\ldots\Up_K(\pub,\up_1)\ldots,\up_n)$ generated by a sequence of update operations applied to the initial representation, there exists another sequence of update operations such that $\Up_K(\ldots\Up_K(\pub',\up'_1)\ldots,\up'_m) = \pub$. In other words, any sequence of updates applied to any representation can be undone by further updates.

\begin{lemma}[Salts do not affect \errep for invertible structures]\label{lemma:noinvsalt}
  Let $\struct = (\Rep, \Qry, \Up)$ be a data structure with a salt randomly initialized at runtime and $\struct'$ be the same structure using a fixed value from the salt space in place of a randomized salt. For every $t, q_R, q_T, q_U, q_H, r\geq 0$, it holds that
  \[
    \Adv{\errep}_{\struct,r}(t, q_R, q_T, q_U, q_H) \leq
    \Adv{\errep}_{\struct',r}(O(t), 1, q_T, q_U+2n(q_R+q_T+q_U), q_H) \,,
  \]
  where $n$ is the longest minimal sequence of update operations needed to generate a data structure in the space.
\end{lemma}
\begin{proof}
Consider an adversary $A$ in the case of a non-salted data structure which makes $q_R$ queries to $\REPO$ and $q_T$ queries to $\QRYO$. We construct an adversary $B$ for the salted case which produces the same errors as follows. First, $B$ initializes a counter $ct$ to 0 and calls the $\REPO$ oracle on the empty set, receiving an empty representation $\pub$ together with the salt used to create the representation. Then $B$ runs $A$, answering its oracle queries as follows. Whenever $A$ makes a query of the form $\REPO(\col)$, $B$ sets $ct \gets ct + 1$ and calls $\UPO$ repeatedly on $\pub$ to transform it into a representation of $\col$. Then $B$ returns the modified $\pub$ to $A$, stores $\col_{ct} \gets \col$, and performs the opposite updates in reverse order to return to the original empty representation $\pub$. If $A$ makes a query of the form $\QRYO(i,\qry)$, $B$ calls $\UPO$ repeatedly to transform $\pub$ into a representation of $\col_i$ and then returns the result of querying its own oracle with $\QRYO(1, \qry)$. Then once again $B$ performs the inverse updates to transform $\pub$ back into the original empty representation. If $A$ queries for $\UPO(i, \up)$, $B$ sets $\col_i \gets \up(\col_i)$ and again uses $\UPO$ queries to transform $\pub$ into a representation of $\col_i$, returns the value of $\pub$, and then performs opposite $\UPO$ queries to return $\pub$ to the empty representation. Finally, $B$ forwards any of $A$'s RO queries to its own RO.

In general this may use as many as $2n(q_R+q_T+q_U)$ update queries, where $n$ is the longest minimal sequence of update operations needed to generate a data structure in the space. Furthermore $B$ succeeds if $A$ does, so the adversaries' advantages are equal.\missingqed
\end{proof}

%\subsection{Immutabilization}

%We say that a structure has `independent representations' if knowing the representation of one set does not provide any additional information about the representation of any other set. More formally, $\Pi$ has independent representations if $\Prob{\Rep_K(\col) = \pub | \Rep_K(\col')}$

%For example, the standard Bloom filter vacuously has independent representations, since the adversary can perfectly predict the representation of any set without needing to see the representation of other sets. A filter which uses true random sampling in place of hash functions also has independent representations, but a filter which uses a secret key need not have independent representations.

%In each of our example structures involving the use of a secret key, we formalize the system using a pseudorandom function. In each correctness proof, the first thing we do is always moving to a game where the pseudorandom functions are replaced by true random functions, since this gives very similar adversarial advantage (assuming the use of a good prf) while making the behavior of the game much easier to reason about.

%In the case of a structure with sufficiently `independent' representations, we may assume without loss of generality that the adversary never calls the $\REVO$ oracle, since doing so can only decrease their probability of success.

%Note that most of the data structures we consider have some degree of per-representation randomness, such as a salt chosen for hash functions. We consider an alternate correctness game that forces this randomness to behave the same across all representations constructed. In particular, any randomly-chosen parameters which would be chosen during the computation of $\REPO$ are selected at the beginning of the game, using the same random distribution, before the adversary makes any oracle queries. The $\REPO$ oracle then uses this fixed value for any random parameters in place of sampling a new random value.

%\begin{lemma}[]\label{lemma:immutabletomutable}
%  Let $\struct = (\Rep, \Qry, \Up)$ be a data structure, and $\struct'$ be the same structure except that any per-representation random parameters are chosen once and fixed across representations. For every $t, q_r, q_T, q_U, q_H, q_V, r \geq 0$, it holds that
%  \[
%    \Adv{\errep}_{\struct,r}(t, q_R, q_T, q_U, q_H, q_V) \leq
%    \Adv{\prf}_F(\advB) + \Adv{\errep}_{\struct',r}(O(t), q_R + q_U, q_T, 0, q_H, 0) \,,
%  \]
%\end{lemma}
%\begin{proof}
%Given an adversary $\advA$ making queries $(q_R, q_U, q_T, q_H)$, we can construct $\advB$ making queries $(q_R+q_U, 0, q_T, q_H)$ which achieves the same advantage.

%For a structure $\Pi$, we denote by $\Pi'$ the same structure with pseudo-random functions replaced by true-random functions. Using conditional probabilities, we have $\Adv{\errep}_{\struct,r}(\advA) \le \Adv{\prf}_F(\advB) + \Adv{\errep}_{\struct_1,r}(\advA)$.

%In the truly random structure $\struct_1$, the representation of a set is simply a randomly-chosen valid representation of that set. Revealing this therefore reveals no new information about any other representations which have been constructed, and so calling $\REVO$ can only decrease an adversary's chance of success. We may now assume $\REVO$ is never called.

%We next modify the structure to $\struct_2$, where all randomized parameters are fixed across representations at the beginning of the experiment, but not revealed to the adversary. We create an adversary $C$ for the correctness experiment on $\struct_2$ which simulates $\advA$ as follows. The adversary $C$ keeps track of a counter $ct$ and list $L$ of indices and simulates $\advA$. When $\advA$ calls $\REPO$, $C$ appends $ct$ to the end of $L$ and then increments $ct$. When $\advA$ calls $\UPO(i,\up)$, $C$ calls $\REPO(\up(\col_{I(i)}))$, sets $L(i) \gets ct$, and increments $ct$. Finally, when $\advA$ calls $\QRYO(i,\qry)$, $C$ calls $\QRYO(L(i),\qry)$. Since $\REVO$ is never called, $C$ need not implement this oracle. Since all queries are called on representations of the same sets, $C$ has the same probability of success as $A$.
%\end{proof}

%If we raise the threshold for what counts as an error, it can only become more difficult for the adversary to succeed, so in fact all error functions of the form $d(x,y) = [|x - y| > c]$ for some constant $c$ also have this upper bound.

%Another obvious alternative is to simply use the Euclidean distance metric, so that $d(x,y) = |x - y|$. Using this notion of error in fact turns out to be at least as good for the adversary as the binary error metric. Any attack in the correctness experiment with error function $d'(x,y) = [|x - y| \ge 1]$ and $r' = r$ performs at least as well against a count-min sketch with error function $d(x,y) = |x - y|$. Similarly, any attack in the game with error function $d'(x,y) = [x - y > 2]$ and $r' = r/2$ performs at least as well in the game with error function $d(x,y) = |x - y|$, and so on for any other binary error function which gives some fixed credit for finding an error which is off from the correct value by at least some minimum constant value. This means that, if $d$ is the Euclidean distance error function and $d_k'$ is the binary function $d_c'(x,y) = [|x - y| \ge c]$, we have $\Adv{\erreps}_{\struct_s,r,d}(t, q_R, q_T, q_U, q_H) \le \Adv{\erreps}_{\struct_s,r/c,d'}(t, q_R, q_T, q_U, q_H)$.

%In fact, not only is the advantage for the Euclidean metric game bounded below by that of the binary-error-function game, the bound is in some cases strict. The fact that the Euclidean error function allows for unboundedly large errors to be produced by a single query provides the adversary with new possible attacks. For example, the adversary can pick a set $\col$ of size $\frac{n}{r}$ and use $\REPO$ to create a sketch containing each element of $\col$ exactly $r$ times. They then use select several values $x \not\in \col$ and use $\QRYO$ to test each $x$'s membership in the representation. A single such mistake is by definition sufficient for the adversary to win the experiment, so the probability of adversarial victory is the same as the probability of an adversary finding a single element that creates a hash collision in each of the $k$ rows of the sketch. Each of the rows acts as a Bloom filter with a single hash function, so the probability of a collision within a single row is on the order of $(1-e^{-n/(rm)})$, and the probability of such a collision in each of $k$ rows is $(1-e^{-n/(rm)})^k$. Over the course of $q_T$ calls to $\QRYO$, the adversarial advantage is the probability that they find a collision in each row for any value of $x$ tested, which is $1-(1-(1-e^{-n/(rm)})^k)^{q_T}$. When $q_T$ is large but the other resource constraints are small, this may exceed the bound for the binary error function given in the theorem above. For example, if $k = 4$, $m = 1024$, $n = 100$, $r = 4$, $q_T = $, $q_R = 1$, and $q_U = q_H = 0$, we find that the bound for the binary error function is _ while the advantage of this attack is about $3.4 \cdot 10^{-4}$.

%

%Depending on the choice of $d$, it is possible no such $c$ exists. One natural choice of $d$ is the Euclidean metric, with $d(x,y) = |x-y|$, but an alternative is to simply define $d(x,y)$ to be 1 if $|x-y| \ge n\epsilon$ and 0 otherwise, where $n$ is the maximum allowed stream size and $\epsilon$ is one of the error parameters. The non-adaptive guarantee for count-min sketch is that each point query has probability no more than $1-\delta$ of producing an error.

%What if the threshold for an error is 1? In other words, the adversary gets a point for every `false positive'. Assuming the hash functions are independent, the false positive probability in a count-min sketch is the same as the probability of getting simultaneous false positives in each of $k$ Bloom filters using a single hash function each, which is $\left(1-e^{-n/m}\right)^k$.

% Note that if there is a linear error function rather than a binary threshold, it becomes even easier for the adversary to produce errors. After all, anything that produces an error in the binary case will also produce an error in the linear case, with the only difference being that the adversary may be able to make the error even worse and get even more `credit' for it later on. This means we have a linear ordering of correctness bounds, with linear-error-function count-min sketches below binary-error-function count-min sketches, which in turn are below counting filters.

%Given that there is a binary error threshold, we can assume without loss of generality that the adversary never adds an element multiple times, since doing so cannot cause additional errors.

% the adversary can: query for a previously-tested element, query for an untested element, insert an unknown element, insert a known correct element, insert a known overestimated element, insert a known underestimated element, delete an unknown element, delete a known correct element, delete a known overestimated element, or delete a known underestimated element

% inserting an unknown element can increase the number of overestimated elements, and can increase the amount they are overestimated by; it can also decrease the number of underestimaged elements, and can decrease the amount they are underestimated by; it does not affect the estimate of the inserted element
% inserting a known correct element does the same thing, and also does not affect the estimate of the inserted element, so this is equivalent to inserting an unknown element

% inserting any element can increase the number of overestimated elements, and can increase the amount they are overestimated by; it can also decrease the number of underestimaged elements, and can decrease the amount they are underestimated by; it does not affect the estimate of the inserted element; the estimate of the element itself remains unchanged
% the opposite is true for deletion
% there is no upper bound on the number of errors that can be caused by a single insertion or deletion(!)
% in particular, deleting an element immediately causes all otherwise-correct elements that overlap at any point to become off by 1 (too low)

% provide the same $\INTO$ as for a counting filter

%Getting rid of the $q_R$ bound in the salted private-representation case...

%We need a salt, since otherwise the adversary can ask for two representations and reveal one to see what the other looks like.

%In fact, we need independent random representations. Once we have this, seeing representations does not help the adversary. What benefit can there be, then? Suppose an adversary wants to select for representations with certain properties, and ignore others. Since the representation is private, these properties can only be determined by $\QRYO$ calls.