%The fact that queries can test not just for set membership, but for frequency, means that new attacks are possible. For example, an adversary can pick a set $\col$ and an element $x \not\in \col$ and use $\REPO$ to create several different sketches representing $\col$. If the $\QRYO$ oracle reveals that $x$ is a false positive (i.e. appears in the filter with nonzero frequency) for any of these, the adversary can use $\UPO$ to insert all the elements of $\col$ an additional $r$ times. Then a single further $\QRYO(x)$ call will produce an error of magnitude $r$, causing the adversary to succeed at the experiment.

%The success rate of this attack depends on $|\col|$. The probability of $x$ being a false positive is given by the standard Bloom filter bound, $(1-e^{-k|\col|/m})^k$ for a $k$-by-$m$ count-min sketch. Since the adversary needs $(r-1)|\col|$ calls to $\UPO$ to produce an error of size $r$

The count-min sketch data structure comes in several varieties which each have slightly different security properties. There are also many possible error functions which can be considered, unlike with set membership queries where all errors are simply false positives or false negatives. Some implementations of count-min sketch allow for elements to be assigned negative frequency (so that the response space is $\Z$), while others do not (so that the response space is $\N$). In the latter case, updates may either include only insertion or may include both insertion and deletion. The easiest error function to work with is a binary error function which gives the adversary 1 point if it discovers a query which is off from the true value by at least some constant $c$, so that $d(x,y) = [|x - y| \ge c]$.

%Of course, $d$ is not an actual parameter of the data structure. Like $r$, it is a part of the security experiment, and measures how bad we consider certain errors to be. There are two `obvious' choices for $d$. First, there may have a certain precision a structure is intended to achieve, and any error outside the acceptable bounds counts as 1 point for the adversary. Second, we could have an error function that scales linearly with the size of the error, such as $d(x,y) = |x - y|$.

As in the case of counting filters, we are forced to make use of a thresholding assumption, namely that the sum of the counters in the sketch must remain below some upper bound $N$.

\begin{theorem}[Correctness Bound for Count-Min Sketch]\label{thm:count-ms-bound}
Fix integers $k, m, n, \lambda, r\geq 0$, a threshold ratio $p \in [0,1]$, and an error function $d(x,y) = [|x - y| > 0]$ for some $c \in \N$.
  For every $t, q_R, q_T, q_U, q_H \geq 0$, it holds that
  \begin{eqnarray*}
    \Adv{\erreps}_{\struct_s,r}(t,&q_R,& q_T, q_U, q_H) \leq \\ && q_R \cdot \left[\frac{q_H}{2^\lambda} + \binom{q_T}{\lceil r/k \rceil}\left(p+\frac{\lceil r/k \rceil}{m}\right)^{k\lceil r/k \rceil}\right] \,,
\end{eqnarray*}
\end{theorem}

\begin{figure}
  \boxThmBFSaltCorrect{0.48}
  {
    \underline{$\G_0(\advA)$}\\[2pt]
      $\col \getsr \advA^H$; $\setC \gets \emptyset$; $\setB \gets \col$; $\err \gets 0$\\
      $\pub \getsr \Rep[\HASHO](\col)$\\
      $\bot \getsr \advA^{\HASHO,\QRYO,\UPO,\INTO}$\\
      return $(\err \geq r)$
    \\[6pt]
    \oraclev{$\QRYO(x)$}\\[2pt]
      $\setB \gets \setB \cup x$\\
      if $x \in \mathcal{C}$ then return $\bot$\\
      $\setC \gets \setC \union \{x\}$\\
      $a \gets \Qry[\HASHO](\pub, x)$\\
      if $a \neq [x \in \col]$ then $\err \gets \err + 1$\\
      return~$a$
    \\[6pt]
    \oraclev{$\UPO(x,b)$}\\[2pt]
      $\setB \gets \setB \cup x$\\
      $\setC \gets \emptyset$\\
      $a \gets \Qry[\HASHO](\pub, \qry_x)$\\
      if $x \in \setC$ and $b = a \neq [x \in \col]$ then\\
      \tab $\err \gets \err-1$\\
      if $b = 1$ then\\
      \tab $\col \gets \col + \{x\}$\\
      else\\
      \tab $\col \gets \col - \{x\}$\\
      $\pub \gets \Up[\HASHO](\pub,\up_{x,b})$\\
      return~$\bot$
    \\[6pt]
    \oraclev{$\HASHO(x)$}\\
      $\hh \getsr [m]^2$; $\vv \gets \fff(\hh$)\\
      if $T[x]$ is defined then $\vv \gets T[x]$\\
      $T[x] \gets \vv$;
      return $\vv$
  }
  {
    \underline{$\G_1(\advA)$}\\[2pt]
    \oraclev{$\INTO(x,y)$}\\
      if $x \not\in \col$ or $y \not\in \col$ then\\
      \tab return $\bot$\\
      $i \gets 0$\\
      for $h$ in $\HASHO(x)$ do\\
      \tab if $h$ in $\HASHO(y)$ then $i \gets i+1$\\
      return $i$
    \\[6pt]
    \underline{$\G_2(\advA)$}\\[2pt]
    \oraclev{$\UPO(x)$}\\
      if $\QRYO(x)$ and $x \not\in \col$ then\\
      \tab $\err \gets \err + \max(k \cdot d(0,1), d(1,0))$\\
      $\setB \gets \setB \cup x$\\
      $\setC \gets \emptyset$\\
      $a \gets \Qry[H](\pub, \qry_x)$\\
      if $x \in \setC$ and $a \neq [x \in \col]$ then\\
      \tab $\err \gets \err-1$\\
      $\col \gets \col + \{x\}$\\
      $\pub \gets \Up[H](\pub,\up_{x,b})$\\
      return~$\bot$
  }
  {
  }
  {
  }
  \caption{Games 0--3 for proof of Theorem~\ref{thm:count-ms-bound}.}
  \label{fig:count-ms-bound}
\end{figure}

\begin{proof}

Applying lemma~\ref{lemma:errep} and lemma~\ref{lemma:salttorand}, we reduce the $\erreps$ experiment to the $\erreps1$ experiment with a salted hash function replaced by true random sampling from $[m]$ for each of the $k$ distinct hash values. This is given in $\G_0$. In $\G_1$, we account for the possibility that the adversary can glean information about the overlap between sets by querying each of them separately. In particular, we give the adversary an additional oracle $\INTO$ that returns the number of locations in which two elements overlap. However, we constrain $\INTO$ to only return an answer when the element has previously been sent to some other oracle.

Because new $\QRYO$ and $\UPO$ calls are based on random sampling, this does not provide the adversary with any additional information about how additional elements which might be queried, inserted, or deleted in the future might behave. However, any element which is sent to $\QRYO$ or $\UPO$ which acts as a false positive will be immediately recognized as such. Because of this, our next step will be to move to a game $\G_2$ where any insertion of a false positive immediately gives the adversary credit for the worst possible error that could be caused by either inserting or deleting that element.

%Define $\delta = \max(k \cdot d(0,1), d(1,0))$ and $\mu = \lceil r/\delta \rceil$.

In $\G_2$, we modify the game so that producing a false positive increments $\err$ by $k$, but so that elements cannot be removed from the set. Because underestimation errors can only be produced by deleting `false positives' (i.e. elements that should have 0 frequency but which are reported to have positive frequency), and the deletion of $n$ false positives can only produce as many as $nk$ underestimation errors, this means that the adversary has no need to cause underestimation errors. Doing so can only decrease the chances of producing additional errors by reducing the values of counters in the sketch, and so this does not decrease the adversary's ability to produce errors. Furthermore, we increase the allowed number of nonzero counters from $mp$ to $mp + k\lceil r/k \rceil$. The only way in which not being able to remove false positives can decrease the adversary's effectiveness is if the maximum capacity of the sketch is reached. Since each false positive removed causes at most 1 nonzero counters to be returned to zero, and the adversary stops after accumulating $r$ errors, an allowance of an extra $\lceil r/k \rceil$ nonzero counters per row is enough to make up for this.

Since each new element queried from outside $\col$ has its corresponding indices determined by a true random function, the adversary can do no better than maximizing the number of nonzero counters in its attempt to produce false positives. Assuming the adversary is able to achieve a maximum-capacity number of nonzero counters, the probability of any particular counter being nonzero is $(mp + \lceil r/k \rceil)/m = p + \frac{1}{m}\lceil\frac{r}{k}\rceil$. Over $k$ total hashes, the probability of a false positive is $\left((mp + \lceil r/k \rceil)/m\right)^k = \left(p + \frac{1}{m}\lceil\frac{r}{k}\rceil\right)^k$. Since the adversary needs to accumulate $\lceil\frac{r}{k}\rceil$ errors over the course of $q_T$ queries, the probability of the adversary succeeding in this game is

$$\Prob{\G_2(\advA) = 1} = \binom{q_U + q_T}{\lceil r/k \rceil}\left(p+\frac{\lceil r/k \rceil}{m}\right)^{k\lceil r/k \rceil}$$

Therefore the advantage of the adversary in the original game is

$$\Adv{\erreps}_{\struct_s,r}(\advA) \le q_R \cdot \left(\frac{q_H}{2^\lambda} + \binom{q_T}{\lceil r/k \rceil}\left(p+\frac{\lceil r/k \rceil}{m}\right)^{k\lceil r/k \rceil}\right).$$\missingqed

%%

%We give the adversary access to an $\INTO$ algorithm that tells the adversary the precise overlap between any combination of elements which have already been queried to $\QRYO$ or $\UPO$, or which were in the original representation. Furthermore, we give the adversary credit for any inaccuracy in the frequency count, not just an innacuracy above the threshold of $\delta$. This can only help the adversary, since any error that existed in the original game is also an error here.

%However, since the `hash functions' in this game are actually true random functions, knowing the overlap between already-queried elements does not give an adversary any advantage in predicting how future elements will be hashed. This game is in fact exactly equivalent to the final counting filter game, where the adversary's chance of success is given by the chances of randomly assembling a filter that produces at least $r$ errors. This probability is given by
%$$\Adv{\erreps}_{\struct_s,r}(\advA) \le q_R \cdot \left(\frac{q_H}{2^\lambda} + \binom{q_T}{\mu}\left(p+\frac{k\mu}{m}\right)^{k\mu}\right).$$

\end{proof}