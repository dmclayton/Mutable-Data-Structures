\begin{figure}
  \twoColsNoDivide{0.22}
  {
    \underline{$\Rep^R_K(\col)$}\\[2pt]
      $\salt \getsr \bits^\lambda$;
      $\pub \gets \langle 0^m, \salt, 0\rangle$\\
      for $x \in \col$ do \\
        $\tab \pub \gets \Up^R_K(\pub, \qry_x)$\\
        $\tab$if $\pub = \bot$ then return $\bot$\\
      return $\pub$
  }
  {
    \underline{$\Qry^R_K(\langle M, \salt, c \rangle,\qry_x)$}\\[2pt]
      $X \gets \bmap_m(R_K(\salt \cat x))$\\
      return $M \AND X = X$
    \\[6pt]
    \underline{$\Up^R_K(\langle M, \salt, c \rangle,\qry_x)$}\\[2pt]
      if $c \geq n$ then return $\bot$\\
      $M \gets M \vee \bmap_m(R_K(\salt \cat x))$\\
      return $\langle M, \salt, c+1 \rangle$
  }
  \caption{Keyed structure $\bloom[R,n,\lambda]$ given by
  $(\Rep^R,\Qry^R,\Up^R)$ is used to define Bloom filter variants used to
  rerpresent sets of at most~$n$ elements.  parameters are a function $R:
  \keys\by\bits^* \to [m]^k$ and integers $n, \lambda \geq0$. A concrete scheme
  is given by a particular choice of parameters. The function~$\bmap_m$ is
  defined in Section~\ref{sec:prelims}.
  %
  }
  \label{fig:bf-def}
\end{figure}
In this section we consider two classes of Bloom filters, each employing a
different strategy to determine when the filter reaches full capacity. The first
class, specified in Figure~\ref{fig:bf-def}, we call the $n$-capped Bloom
filter. This class captures the classical definition of a Bloom filter which is
capped at storing some fixed constant number of elements $n\geq0$. Our
construction $\bloom[R,\ell,n,\lambda] = (\Rep^R,\Qry^R,\Up^R)$ has two
additional parameters besides the cap: a function~$R:\keys\by\bits^*\to[m]^k$
and the \emph{salt length}~$\lambda\geq0$.
%
Let $H:\bits^*\to[m]^k$ be a hash function and let $\ell, n, \lambda\geq0$ be
integers.
%
The standard Bloom filter is the structure $\BF[H,n] =
\bloom[\id^H,n,0]$, which we will term the \emph{basic} Bloom filter. It
has no key (the key sapce of $\id^H$ is $\{\emptystr\}$, see
Section~\ref{sec:prelims}) and does not use a salt.
%
The \emph{salted} Bloom filter $\SBF[H,n,\lambda] =
\bloom[\id^H,n,\lambda]$ is the same except that it allows a nonempty salt.
%
We also consider a salted variant that uses a PRF instead of a hash
function. The \emph{keyed} Bloom filter $\KBF[F,n,\lambda]$ is the
structure $\bloom[F,n,\lambda]$, where $F:\keys\by\bits^*\to[m]^k$ is a
PRF.
%
Note that the basic and salted BFs have key spaces $\{\emptystr\}$ and the keyed
BF has key space~$\keys$.

In this section, we will show that the basic Bloom filter construction
$\BF[H,n]$ is flawed, allowing the adversary to make an offline attack that
has a high probability of success while using a minimal number of queries. In
the immutable setting, where the adversary is constrained to never use the
$\UPO$ oracle, i.e. $q_U = 0$, it suffices to use the $\SBF$ construction in
order to provide a good security guarantee in either the public-representation
or private-representation settings. However, in the case where we allow
$q_U > 0$ so that the adversary can make updates, we will find that $\SBF$ is
not secure in the public-representation setting. Instead, $\KBF$ must be used to
guarantee security.

At the end of the section, we discuss the second class of filter, we call the
$\ell$-thresholded filter. This construction uses a \emph{filter threshold}
$\ell\geq0$ in place of the set threshold, which bounds the number of bits in
the filter that can be set to 1 instead of the number of elements in the
underlying set. In the absence of an adaptive adversary this construction
performs very similarly to the standard Bloom filter, since for a random input
set the number of bits set to 1 can be predicted with a high degree of accuracy
from the number of elements in the underlying set. However, a filter threshold
allows us to obtain better bounds against adaptive adversaries and has the
additional advantage of not requiring a separate counter to keep track of the
number of elements in the filter. Each of the above special cases can be
extended to the filter-threshold construction in the natural way, though we only
consider the unkeyed and salted construction $\SBF_\mathrm{ft}$ to provide an example
of the tighter error bounds this alternate construction can provide.


\heading{Non-adaptive false-positive probbility.}
Let~$\rho$ be a function, $\lambda\geq0$ be an intger, and define
$\bloom[\id^\rho,n,\lambda] = (\Rep^\rho, \Qry^\rho, \Up^\rho)$ as in
Figure~\ref{fig:bf-def}. (Note the mild abuse of notation by which we write
``$\rho$'' instead of ``$\id^\rho$''.)
%
Let $\setS\subseteq\bits^*$ be a set of length~$n$ and let
$x\in\bits^*\setminus\setS$. We define the non-adaptive, false positive
probabiity for Bloom filters as
\begin{equation}\label{eq:bf-fp}
  \begin{aligned}
    P_{k,m}(n) =
      \Pr\big[&\rho \getsr \Func(\bits^*,[m]^k);
              \pub \getsr \Rep^\rho(\setS): \\
              &\Qry^\rho(\pub, \qry_x) = 1 \given \pub \ne \bot
      \big] \,.
  \end{aligned}
\end{equation}
%
(Note that, since the probability is conditioned on the event that
$\pub\ne\bot$, this quantity is the same for both classes of filter.)
%
That is, $P_{k,m}(n)$ is the probability some~$x$ a false positive for the
representation of some~$\setS$ for which $|\setX|=n$ and $x\not\in\setS$, when a
random function is used for hashing.
%
Deriving a tight, concrete upper bound is elusive; \todo{DC}{Briefly comment
on why this is difficult.} However, we do understand its asymptotic behavior
quite well. Kirsch and Mitzenmacher~\cite{kirsch2006less} prove that, for
particular choices of $k$ and $m$ as functions of~$n$, it holds that
$
  P_{k,m}(n) = \lim_{n\goesto\infty} (1-e^{-kn/m})^k \,.
$
%
Moreover, they demonstrate via simulation that this is a very good approximation
of the false positive probability for parameters of practical interest.
%
In lieu of a concrete upper bound, we will refer to $P_{k,m}(n)$ as defined in
Equation~(\ref{eq:bf-pf}) in the remainder of this section.

\heading{Error function for set-mempership queries}
%
Throughout this section we will use the error function~$\delta$ defined as
\begin{equation}
  \delta(x, y) =
  \begin{cases}
    0 & \text{if}\ x=y \\
    1 & \text{otherwise.}
  \end{cases}
\end{equation}
This simply indicates whether the query result matched the correct response.

\subsection{Insecurity of unsalted BFs}
Fix a hash function $H:\bits^*\to[m]^k$ and integer $n\geq0$ and
let $\Pi = \BF[H,n]$.
%
Suppose the adversary is interacting with a system representing a dataset
with~$\Pi$ and that it is able to choose some fraction of the input data.  For
example, consider a web crawler which performs a `crawl' of webpages, following
the links on each page it visits in order to index, archive, or otherwise
analyze websites. In order to keep track of the set of webpages which have
already been visited during a crawl, some crawlers use a Bloom filter which is
updated to include each new page the crawler visits. Suppose the adversary
controls at least one such webpage along the crawl's path and wishes to deny the
spider access to a different webpage, the `target webpage'. The adversary can
choose the links present on its own webpage, which will cause the spider to
visit the chosen webpages and set the corresponding bits of its Bloom filter to
1. If those links are chosen in such a way that they produce a false positive
for the target webpage, the spider will then erroneously believe it has already
visited the target webpage. The target webpage will therefore never be visited
during the spider's crawl.

\heading{Pollution attacks}
%
\ignore{\cpnote{Overall, I think this part needs to be revised to make it more clear.
Answer the following questions. (1) How does their attack model compare to ours,
i.e., are pollution attacks effective in the sense of \errep? (2) What makes
their attacks possible? Is is it the use of weak (non-cryptographic) hash
functions? How dependent is their attack on controlling a fraction of the
inputs? Do they assume that the inputs they don't control are \emph{known} to
the adversary? (3) Are their mitigigations sufficient for security in the sense
of \errep, or is their an attack? (The answer is there's an attack: target-set
coverage)}}
%
The goal of the attacks pointed out by Gerbet \etal~~\cite{gerbet2015power} is
to pollute the filter such that the ``average'' set-membership query yields a
false positive with high probability; to do so, the attacker chooses a set of
inputs that maximize the number of 1s in the filter. This strategy is especially
effective when the structure of the hash function is known to the adversary. In
particular, as long as the choice of hash function and any associated parameters
are public, the adversary can compute the hash function on its own in order to
determine which choices will set the maximum number of bits to 1, or which
choices will set certain target bits to 1 in order to cause specific false
positives. They show that with $m = 3200$ and $k = 4$, the adversary can double
the false positive rate if they control 200 out of a total of $n = 600$
insertions.

Significantly, the attack model considered assumes that the representations of
the filter are always kept private. This gives the adversary less power than in
our \errep\ or even \erreps\ attack model, since there is no analogue to the
$\REVO$ oracle. Within this model, Gerbet \etal show various ways to mitigate
pollution attacks, such as choosing the parameters of the filter pesimistically,
so that even if a pollution attack occurs, the false positive rate is kept below
some threshold of acceptability. This strategy is  potentially viable, but may
significantly increase the amount of memory required to store the data structure.
The bounds we provide show how the parameters of a filter can be tweaked to keep
the error rate low not just in the presence of this specific type of attack, but
in the presence of any adversary covered by our more general attack model.

The authors also discuss the possibility of using a secretly-keyed
hash function. In the attack model they consider, where representations are kept
private indefinitely, this suffices to prevent the pollution attack they
describe. However, under the more general attack models where the representation
may eventually be recovered (in the private-representation setting) or is simply
available to potential adversaries (in the public-representation setting).
Simply using a MAC with a long-term secret key does not suffice to
secure a Bloom filter in the \errep\ and \erreps\ scenarios we consider.

\heading{Target-set coverage attacks}
%
Of course, exhibiting a high false positive rate is not the only way a Bloom
filter might fail to be correct. In particular, it would be undesirable if the
filter were consistently incorrect on a \emph{particular set of inputs}. Rather
than pollute the filter, the adversary's goal might be to craft a set of
legitimate looking inputs that cover some disjoint target set of inputs.
%
This type of attack is nicely captured by our adversarial model.
%
In a \emph{target-set coverage attack}, the adversary is given a small target set
$\setT\subseteq\bits^*$ and searches for a cover set $\setR\subseteq\bits^*$
such that $\Qry^H(\Rep^H(\setR),\qry_x)=1$ for each $x\in\setT$.
%
Once a suitable cover set is found, the adversary queries $\Rep(\setR)$. Then
for each $x\in\setT$, it asks $\Qry(x)$, achieving a score of $r = |\setT|$.

This \erreps1 attack succeeds with probability~$1$ assuming a covering set can
be found.  If $|\setT| \leq |\setR|$, then such a set exists; but finding it may be
computationally infeasible, depending on the size of the cover set, the size of
the target set, and the parameters of the Bloom filter.
%
In Appendix~\ref{app:unsalted-attack} we demonstrate that target-set coverage
attacks are feasible for practical BF parameters. We do so by simulating the
attack when~$H$ is a random function (i.e., for each distinct input we choose
$k$ integers from $[m]$ at random) for typical choices of $k$, $m$, and~$n$.
%
\todo{CP}{Add simulation to appendix.}

The key to pollution attacks and target-set coverage attacks is that the
adversary can compute the representation of the set on its own. In the remainder
of this section, we examine ways of enhancing the basic BF structure so that it
avoids this pitfall.

\subsection{Salted BFs in the (im)mutable setting}
%
Here we consider the correctness of Bloom filters when the hashed input is
preppended with a salt.
%
Fix $H:\bits^*\to[m]^k$ and $n,\lambda\geq0$ and let
$\Pi = \SBF[H,n,\lambda]$.

\ignore{\todo{DC}{Simplify the description of this attack, as well as the next
paragraph. Simply say that, given the salt, the adversary can construct the
representation on its own, just as in the attacks described in the previous
section.}}

In the mutable setting, we can perform an \errep\ attack against~$\Pi$ in an
almost identical manner to the previous section. If the adversary calls
$\REPO(\emptyset)$, the salt will be given to the adversary along with an empty
filter. The adversary can use this salt to construct representations on its own
just as described in the target-set coverage attack. The only further alteration
is that the adversary will need to use $\UPO$ to insert the elements of the
covering set into the filter before making its $\QRYO$ calls to win the game.
This attack succeeds whenever the original pollution attack succeeds against an
unsalted filter.

The attack succeeds because the adversary can search for false positives on its
own as soon as it learns the salt. An adversary in the real world may not be
able to perform this exact attack, since even in the streaming setting it is
possible that the salt is not immediately revealed to the adversary. However, as
soon as the adversary does learn the salt, it can immediately launch a pollution
attack against the filter, without having to make any queries directly to the
filter. Just as in the immutable setting the adversary can exploit its knowledge
of the hash functions to find false positives without needing to make queries,
in the mutable and public-representation setting the adversary can identically
exploit its knowledge of the hash functions \textit{and salt} to find false
positives without needing to make queries.

\ignore{
The security of this structure depends upon how it is used.
%
\todo{DC (lead)}{As concisely as you can, articulate the \errep\ attack against~$\Pi$.
Remember that the adversarial model (i.e., the security experiment) is supposed
to reflect how the primitive is supposed to be used. So when giving attacks, try
to make it clear what the attack is. You should answer the following questions:
What is the sequence of queries made by the adversary?
How efficient is the attack?
Is the attack devastating? Is it a real attack, or is it more theoretical?
What about the scheme and setting make it possible?
%
Note that I've left your text in a ignore\{\} so that you can lift from it as
needed.
}
The use of a salt without a private key in the \errep\ setting is
insufficient to defeat [the attacka above]. In this setting, the adversary need only
make its $\REPO$ query for $\setT$ in advance, at which point it will receive
both the representation $\pub$ and the salt $\salt$ used to construct it. Using
this known salt, the adversary is still able to simulate $\REPO$ for arbitrary
singleton representations. The previous attack therefore still works with the
same (minimal) number of $\QRYO$ calls at the very end of the experiment, after
it has determined $\setR$ using offline computations.
\cpnote{I don't think this is true, since each $\ROPO$ query returns a filter
with a different, independently generated salt.}

The opposite of this, using a private key without a salt, does weaken the attack
somewhat. Even with public representations, the adversary cannot locally
simulate $\REPO$ without guessing the private key. However, they can still
outperform random $\QRYO$ calls by making $\REPO$ queries for singleton elements
without fixing any $\setT$ in advance. After selecting a random set $\col$ of
size $q_R-1$, the adversary performs offline computations to find $\setT$,
$\setR \subseteq \col$ such that the elements of $\setR$ are false positives for
the representation of $\setT$ (which can be computed from the representations of
the singleton subsets of $\setT$). The adversary wins if there is a partition
where $\setR$ produces at least $r$ errors on $\REPO(\setT)$.
\cpnote{This might be the case, but I don't think it's worth spending too much
time on. We're going to have other reasons for needing to add salt even when
there's a key.}

Using a salted Bloom filter in the private representation setting, however, does
provide some security. At the time a representation is created, the structure
chooses a salt $\salt$ which it will use for all further queries and updates. In
order for maximum security to be guaranteed, we must ensure that the
representation, and in particular the salt, is kept secret from the adversary.
We define this structure $\SBF[H,k,m,n,\lambda]$ as the Bloom filter structure
that uses $H(s) = (h_1(s),\ldots,h_k(s))$ for hashing inputs to $k$ values in
$[m]$. Furthermore, each call of $\Rep$ first involves picking a salt $\salt$
from the salt space $\bits^\lambda$, and all hashes made to insert or query for
an element $x$ are determined using $H(x \Vert \salt)$. Finally, the parameter
$n$ means that any attempts to represent sets with more than $n$ elements fail.
\todo{DC lead}{Specify what exactly is being analyzed.  What are the updates?}
}

Without this exploitation of mutability, and in particular the ability to insert
elements even after the salt has been seen, the above attack fails. Indeed, when
we restrict ourselves to the immutable setting, we can prove the following.
%
\begin{theorem}[Immutable \errep\ security of salted BFs]\label{thm:sbf-errep-immutable}
  For all integers $q_R, q_T, q_H, r, t \geq 0$ it holds that
  \begin{equation*}
    \begin{aligned}
            \Adv{\errep}_{\Pi,\delta,r}(t,\,&q_R,q_T,0,q_H) \leq \\
        & q_R \cdot \left[\frac{q_H}{2^\lambda} +
        \left(\frac{pq}{r}\right)^re^{r-pq}\right] \,,
    \end{aligned}
  \end{equation*}
  where $H$ is modeled as a random oracle, $p=P_{k,m}(n)$, $q = q_T + q_H$, and
  $p > pq$.
\end{theorem}
We consider only the case of $r > pq$ because $pq$ is the expected number of
false positives obtained by an adversary that simply uses its knowledge of the
salt (after the representation is created) to guess as many random elements as
possible. Because this simple adversary can get $pq$ successes on average, we
can only hope to provide good security bounds against arbitrary adversaries in
the case that $r > pq$.

This bound can be broken down into three main components. The multiplicative
factor of~$q_R$ means that the bound will be weak in the case that a number of
representations are used. The $q_H/2^\lambda$ term corresponds to the
probability of the adversary guessing the salt before the representation is
constructed, but this will be negligible as long as $\lambda$ is chosen to be
sufficiently large (say, $\lambda=128$). The final, messier term comes from
applying a Chernoff bound to the non-adaptive adversary's probability of
succeeding in the experiment given $q = q_H+q_T$ guesses.
%
By way of clarifying the performance of our bound, we have plotted the last
component for various parameters of interest. Let
%
\begin{equation}\label{eq:zeta}
  \zeta_{k,m,n}(q,r) = \left(\frac{p^*q}{r}\right)^re^{r-p^*q}
\end{equation}
%
where
$
  p^* = \lim_{n\goesto\infty} (1-e^{-kn/m})^k \,,
$
the approximation of the non-adaptive false positive probability given by Kirsch
and Mitzenmacher~\cite{kirsch2006less}.
%
Figure~\ref{fig:bf-bound} shows values
of~$\zeta_{k,m,n}(q,r)$ for varying~$m$.
%
What this plot shows is that, for a given error capacity~$r$, once a certain lower
bound on the filter size is reached, the $\zeta$ term decreases quite quickly.
Moreover, the rate at which~$\zeta$ decreases scales nicely with the error
capacity.  For example, if one is willing to tolerate up to~$r=10$ false
positives for a filter representing $n=100$ elements, then picking a filter
length of $3$ kilobytes is sufficient to ensure that observing~$10$ false
positives occurs with probability less than $2^{-17}$, even when the adversary
can make~$2^{64}$ RO queries.
%
We compare this (rather conservative) result to Gerbet \etal at the end of this section.

\begin{figure}
  \hspace*{-10pt}
  \includegraphics{fig/bf-bound}
  \vspace{-24pt}
  \caption{
    The value of $\zeta_{k,m,n}(q,r)$ (Equation~\ref{eq:zeta}) for $q=2^{64}$,
    $k=16$, $n=100$, varying values of~$r$ (one line per $r$-value) and filter
    length~$m$ (the x-axis).  Note the log-2 scale on the y-axis.
  }
  \label{fig:bf-bound}
\end{figure}

\begin{proof}[Proof of Theorem~\ref{thm:sbf-errep-immutable}]
  \input{proof/sbf-errep-immutable}
\end{proof}


Recall that the attack against mutable salted filters exploited the fact that
the adversary learned the salt as soon as the filter was created, and that from
this it could compute the hash function on its own. Even if the filter is
mutable, we can prevent this attack from working as long as we require that the
filter under attack be kept secret from adversaries. In fact, we can attain the
following \erreps\ bound.

\begin{theorem}[\erreps\ security of salted BFs]\label{thm:sbf-erreps}
  Let $p' = P_{k,m}(n+r)$.
  For all integers $q_R, q_T, q_H, r, t \geq 0$, if
  $r > p'q_T$, then it holds that
  \begin{eqnarray*}
    \begin{aligned}
      \Adv{\erreps}_{\Pi,\delta,r}(t,\,&q_R, q_T, q_U, q_H) \leq \\
          & q_R \cdot \left[
      \frac{q_H}{2^\lambda} +
      \left(\frac{p'q_T}{r}\right)^re^{r-p'q_T}\right]\,,
    \end{aligned}
\end{eqnarray*}
  where $H$ is modeled as a random oracle.
\end{theorem}

The proof follows a similar structure to that of
Theorem~\ref{thm:sbf-errep-immutable}. The primary differences come from arguing
that without a ``lucky'' guess of the salt the adversary cannot use offline hash
queries to find false positives, and from having to show that the adversary's
access to $\UPO$ does not substantially change the security bound that can be
derived. The first of these is straightforward given the private-representation
setting, but the second requires investigating how much of an advantage the
$\UPO$ oracle can give in a pollution attack, and then moving to games where
this advantage is taken into account.

\begin{proof}[Proof of Theorem~\ref{thm:sbf-erreps}]
  \input{proof/sbf-erreps}
\end{proof}

\subsection{Keyed BFs}

Salted BFs are \erreps\ secure in general, and are \errep\ secure in the
immutable setting, but are not \errep\ secure when the adversary has access to
an $\UPO$ oracle. Our argument for the \erreps\ security of
salted Bloom filters is made possible by virtue of the structure under attack
not being revealed to the adversary. While this is realistic in many
applications, it may be desirable for the Bloom filter to be public \emph{and}
updatable.
%
Here we show that building a Bloom filter from a PRF suffices for security in
this setting.
%
Let $F:\keys\by\bits^*\to[m]^k$ be a function, fix
integers~$n,\lambda\geq0$, and let $\Pi = \KBF[F,n,\lambda]$.

\begin{theorem}[\errep\ security of keyed BFs]\label{thm:bf-key-bound}
  Let $p' = P_{k,m}(n+r)$.  For integers $q_R, q_T, q_H, r, t \geq 0$ such that
  $r > p'q_T$, it holds that
  \begin{equation*}
    \begin{aligned}
      \Adv{\errep}_{\Pi,\delta,r}(t,\,&q_R,q_T,q_U,q_H) \leq \\
        \Adv{\prf}_F(t,nq_R+q_T+q_U) & +
      \frac{q_R^2}{2^\lambda} +
      \left(\frac{p'q_Rq_T}{r}\right)^re^{r-p'q_Rq_T} \,.
    \end{aligned}
  \end{equation*}
\end{theorem}

Though the bound is similar, the details of this proof differ from the
previous two. In particular, since we are using a PRF, the initial parts of the
proof deal with the adversary potentially being able to break the PRF and with
the possibility of the salts repeating rather than with the adversary being able
to guess the salt.

\begin{proof}
  \input{proof/kbf-errep}
\end{proof}

The fact that both a key and a salt are used in the $\KBF$ construction is
critical. In particular, without the per-representation randomness given by the
salt, we would not be able to argue that $\UPO$ and $\QRYO$ calls are
independent across representations. On the contrary, seeing the representation
of a singleton set $\{x\}$ would immediately allow the adversary to test whether
$x$ was a member in every other representation that had been constructed, simply
by testing whether every bit set to 1 in the representation of $\{x\}$ was also
set to 1 in other representations. Even in the \erreps\ game, using the $\REVO$
oracle on some representations leaks information about other representations,
and again we cannot use the argument that provides the above bound.

We note that Gerbet \etal~\cite{gerbet2015power} suggest using cryptographic
hash functions as one possibility for constructing secure filters, which is
equivalent in our terminology to using a keyed but unsalted filter. The
distinction is that Gerbet \etal assume that representations are kept private
indefinitely, an assumption similar to that underlying our \erreps\ game but
with the stronger restriction that the adversary has no equivalent of a $\REVO$
oracle. Without this assumption that representations are never leaked to the
adversary, however, we emphasize that merely using a long-term secret key
without a per-representation salt does not guarantee security.

\subsection{$\ell$-threshold BFs}

\begin{figure}
  \twoColsNoDivide{0.22}
  {
    \underline{$\Rep^R_K(\col)$}\\[2pt]
      $\salt \getsr \bits^\lambda$;
      $\pub \gets \langle 0^m, \salt\rangle$\\
      for $x \in \col$ do\\
        $\tab \pub \gets \Up^R_K(\pub,\qry_x)$\\
        $\tab$if $\pub = \bot$ then return $\bot$\\
      return $\pub$
  }
  {
    \underline{$\Qry^R_K(\langle M, \salt \rangle,\qry_x)$}\\[2pt]
      $X \gets \bmap_m(R_K(\salt \cat x))$\\
      return $M \AND X = X$
    \\[6pt]
    \underline{$\Up^R_K(\langle M, \salt \rangle,\qry_x)$}\\[2pt]
      if $\hw(M) > \ell$ then return $\bot$\\
      return $\langle M \vee \bmap_m(R_K(\salt \cat x)), \salt \rangle$
  }
  \caption{A slightly modified structure, $\bloom_\mathrm{ft}[R,\ell,\lambda]$ given by
  $(\Rep^R,\Qry^R,\Up^R)$ which uses the Hamming weight of the filter ($\hw$, as
  defined in Section~\ref{sec:prelims}) to decide if the filter is full.}
  \label{fig:bft-def}
\end{figure}

While the above proofs show security bounds for Bloom filters in certain
settings, the bounds may not be as tight as we would like for applications. The
extra factor of $q_R$ in the error bound, for example, may prevent a filter from
achieving good security in practice. We show that a stronger bound can be
achieved using the tweaked Bloom filter construction $\SBF_\mathrm{ft}$, showing
a better bound in the private-representation setting than we had for $\SBF$.
%
\cpnote{When a reviewer read this they'll think: ``why, then, do I care about
$n$-capped filters if $\ell$-threshold filters perform so much better?''}

%
\begin{theorem}[\errep\ security of thresholded BFs]\label{thm:bf-thr-bound}
Let $p_\ell = ((\ell+k)/m)^k$. For integers $q_R, q_T, q_H, r, t \geq 0$ such
that $r > p_\ell q_T$, it holds that
  \begin{equation*}
    \begin{aligned}
      \Adv{\errep}_{\Pi,\delta,r}(t, q_R,q_T,q_U,q_H) &\leq \\
        & \frac{q_R(q_H+q_R)}{2^\lambda} + e^{r-p_\ell q_T}\left(\frac{p_\ell q_T}{r}\right)^r.
    \end{aligned}
  \end{equation*}
\end{theorem}

The distinction between this proof and the proofs for the standard Bloom filter
construction lies in the fact that pollution attacks cannot set more than
$\ell+k$ bits of the filter to 1, regardless of how the attack is conducted.
We therefore assume that the adversary will always be able to produce such a
maximally full filter, and then use a standard binomial-distribution-based bound
to place a limit on the adversarial advantage even in this worst-case scenario.
%
\cpnote{It sounds like you're claiming that pollution attacks are the best the
adversary can do. If this is the case, then you have to prove this.}

\begin{proof}
  \input{proof/sbf-erreps-th}
\end{proof}


\subsection{Discussion}
\todo{DC}{At a high level, our suggested mitigation is to use salt and to use a
cryptographically strong hash function, but the exact strategy depends on the
setting. If you aren't going to update the structure, then salting is
sufficient. If you're going to update the structure, then salting is still
efficient as long as the structure is never revealed to attacker (i.e., the
party or parites choosing the inputs). If keeping the structure secret isn't
possible, then you need to also use a secret key. How does this mitigation
strategy compared to the mitigations suggested by Gerbet \etal? In particular,
are our filters smaller, larger, or about the same length as theirs?}

\cpnote{How does the $\ell$-threshold bound compare to that of $n$-capping?}