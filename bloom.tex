\begin{figure}
  \twoColsNoDivide{0.22}
  {
    \underline{$\Rep^R_K(\col)$}\\[2pt]
      if $|\col| > n$ return $\bot$\\
      $\salt \getsr \bits^\lambda$\\
      $M \gets \bigvee_{x \in \col} \bmap_m(R_K(\salt \cat x))$\\
      if $w(M) > \ell$ then return $\bot$\\
      return $\langle M, \salt \rangle$
  }
  {
    \underline{$\Qry^R_K(\langle M, \salt \rangle,\qry_x)$}\\[2pt]
      $X \gets \bmap_m(R_K(\salt \cat x))$\\
      return $M \AND X = X$
    \\[6pt]
    \underline{$\Up^R_K(\langle M, \salt \rangle,\qry_x)$}\\[2pt]
      if $\hw(M) > \ell$ then return $\bot$\\
      return $\langle M \vee \bmap_m(R_K(\salt \cat x)), \salt \rangle$
  }
  \caption{The keyless structure $\bloom[R,\ell,n,\lambda]$ given by
  $(\Rep^R,\Qry^R,\Up^R)$ is used to define Bloom filter variants. The
  parameters are a function $R: \keys\by\bits^* \to [m]^k$ and integers $\ell, n,
  \lambda \geq0$. A concrete scheme is given by a particular choice of
  parameters.  Functions~$\hw$ and~$\bmap_m$ are defined in
  Section~\ref{sec:prelims}.
  }
  \label{fig:bf-def}
\end{figure}


\medskip
We specify three Bloom filter variants using the keyed structure
$\bloom[R,\ell,n,\lambda] = (\Rep^R,\Qry^R,\Up^R)$ specified in
Figure~\ref{fig:bf-def}.
%
The construction has four paraemters: a function~$R:\keys\by\bits^*\to[m]^k$, the
\emph{update threshold} $\ell\geq0$, the \emph{initial threshold} $n\geq0$, and
the \emph{salt length}~$\lambda\geq0$.
%
Let $H:\bits^*\to[m]^k$ be a hash function and let $\ell, n, \lambda\geq0$ be
integers.
%
The standard Bloom filter is the structure $\BF[H,\ell,n] =
\bloom[\id^H,\ell,n,0]$, which we will term the \emph{basic} Bloom filter. It
has no key (the key sapce of $\id^H$ is $\{\emptystr\}$, see
Section~\ref{sec:prelims}) and does not use a salt.
%
The \emph{salted} Bloom filter $\SBF[H,\ell,n,\lambda] =
\bloom[\id^H,\ell,n,\lambda]$ is the same except that it allows a nonempty salt.
%
Finally, we also consider a salted variant that uses a PRF instead of a hash
function. The \emph{keyed} Bloom filter $\KBF[F,\ell,n,\lambda]$ is the
structure $\bloom[F,\ell,n,\lambda]$, where $F:\keys\by\bits^*\to[m]^k$ is a
PRF.
%
Note that the basic and salted BFs have key spaces $\{\emptystr\}$ and the keyed
BF has key space~$\keys$.

In this section, we will show that the basic Bloom filter construction
$\BF[H,\ell,n]$ is flawed, allowing the adversary to make an offline attack that
has a high probability of success while using a minimal number of queries. In
the immutable setting, where the adversary is constrained to never use the
$\UPO$ oracle, i.e. $q_U = 0$, it suffices to use the $\SBF$ construction in
order to provide a good security guarantee in either the public-representation
or private-representation settings. However, in the case where we allow
$q_U > 0$ so that the adversary can make updates, we will find that $\SBF$ is
not secure in the public-representation setting. Instead, $\KBF$ must be used to
guarantee security.

\ignore{%
The standard Bloom filter shows a variety of different behaviors depending on
its exact implementation. If the hash functions used are chosen beforehand and
potentially known to the adversary, this public information allows offline
attacks to be mounted against the data structure which can produce potentially
damaging false positives. In the case of immutable Bloom filters, making use of
a per-representation salt is sufficient to prevent these attacks, though
depending on the use case the use of non-fixed per-representation randomness may
or may not be feasible. Furthermore, in the case of mutable Bloom filters there
are additional difficulties with offline attacks due to adversarially-chosen
updates. To guarantee correctness in this case we must additionally guarantee
that representations can be kept private from the adversary.
}

In the non-adaptive setting, the false positive rate for a Bloom filter of $m$
bits using $k$ hash functions and storing $n$ items can be closely approximated
as $(1-e^{-kn/m})^k + O(1/m)$.~\cite{kirsch2006less} Over the course of $q_T$
random evaluations of $\Qry$, we would then expect about
$q_T((1-e^{-kn/m})^k + O(1/m))$ false positives to occur. Our goal is to
minimize the probability that even an adaptive adversary can perform
significantly better than this lower bound.

The standard definition of a Bloom filter does not make use of a threshold
$\ell$ on the number of 1s in the filter. In practice the close relationshop
between the size of the set and the number of 1s in the representation given by
the Kirsch and Mitzenmacher bound means that that the behavior of the filter in
the absence of an adversary will be almost identical for reasonable choices of
$\ell$. On the other hand, in the presence of an adversary that has access to
$\UPO$ the use of $\ell$ allows us to make stronger guarantees with cleaner
error bounds than would otherwise be possible. If the adversary does not have
access to $\UPO$, i.e. if $q_U = 0$, we will assume an $\ell$ which is large
enough to not affect the behavior of the filter at all, in order to model actual
practice as closely as possible.

\heading{Error function for set-mempership queries}
%
Throughout this section we will use the error function $\delta:\bits^2\to\N$
defined as
\begin{equation*}
  \delta(a, b) =
  \begin{cases}
    0 & \text{if}\ a=b \\
    1 & \text{otherwise.}
  \end{cases}
\end{equation*}

\subsection{Insecurity of unsalted BFs}
Fix a hash function $H:\bits^*\to[m]^k$ and integers $n\geq0$,$\ell = kn$ and
let $\Pi = \BF[H,\ell,n] = (\Rep^H, \Qry^H, \Up^H)$.
%
Suppose the adversary is interacting with a system representing a dataset
with~$\Pi$ and that it is able to choose some fraction of the input data.
For example, some web spiders use Bloom filters to store the set of webpages
which have already been visited during a crawl. Suppose the adversary controls
at least one such webpage and wishes to deny the spider access to a different
webpage, the `target webpage'. The adversary can choose the links present on its
own webpage, which will cause the spider to visit the chosen webpages and set
the corresponding bits of its Bloom filter to 1. If those links are chosen in
such a way that they produce a false positive for the target webpage, the spider
will then erroneously believe it has already visited the target webpage. The
target webpage will therefore never be visited during the spider's crawl.

\heading{Pollution attacks}
%
The goal of the attacks pointed out by Gerbet \etal~~\cite{gerbet2015power} is
to pollute the filter such that the ``average'' set-membership query yields a
false positive with high probability; to do so, the attacker chooses a set of
inputs that maximize the number of 1s in the filter. This strategy is especially
effective when the structure of the hash function is known to the adversary. In
particular, if a secretly-keyed cryptographically-secure function is not used,
the adversary can compute the hash function on its own in order to determine
which choices will set the maximum number of bits to 1, or which choices will
set certain target bits to 1 in order to cause specific false positives. They
show that with some reasonable parameter choices, the adversary can double the
false positive rate if they control a third of the inputs to the filter.
%

Gerbet \etal discuss multiple ways to mitigate pollution attacks, including
using alternate data structures besides Bloom filters or choosing the parameters
of the filter pesimistically, so that even if a pollution attack occurs, the
false positive rate is kept below some threshold of acceptability. Both of these
possibilities are potentially viable, but can significantly increase the amount
of memory required to store the data structure. Since Bloom filters are designed
to store large amounts of data compactly, these solutions may be unnaceptable in
practice. The authors also discuss the possibility of using a secretly-keyed
hash function. Since they assume that the filter itself is kept entirely
private, with no potential for long-term leakage or other phenomena modeled by
our $\REVO$ oracle, this does not fall prey to the attacks against keyed but
unsalted filters that occur in our model. In this paper we consider the
possibility that the structure may not be secret, either in the sense that it
may eventually be recovered (in the private-representation setting) or that it
is publicly available to potential adversaries (in the public-representation
setting). Simply using a MAC with a long-term secret key does not suffice to
secure a Bloom filter in these scenarios.

\heading{Target-set coverage attacks}
%
Of course, exhibiting a high false positive rate is not the only way a Bloom
filter might fail to be correct. In particular, it would be undesirable if the
filter were consistently incorrect on a \emph{particular set of inputs}. Rather
than pollute the filter, the adversary's goal might be to craft a set of
legitimate looking inputs that cover some disjoint target set of inputs.
%
This type of attack is nicely captured by our adversarial model.
%
In a \emph{target-set coverage attack}, the adversary is given a small target set
$\setT\subseteq\bits^*$ and searches for a cover set $\setR\subseteq\bits^*$
such that $\Qry^H(\Rep^H(\setR),x)=1$ for each $x\in\setT$.
%
Once a suitable cover set is found, the adversary queries $\Rep(\setR)$. Then
for each $x\in\setT$, it asks $\Qry(x)$, achieving a score of $r = |\setT|$.

This \erreps1 attack succeeds with probability~$1$ assuming a covering set can
be found.  If $|\setT| \leq |\setR|$, then such a set exists; but finding it may be
computationally infeasible, depending on the size of the cover set, the size of
the target set, and the parameters of the Bloom filter.
%
In Appendix~\ref{app:unsalted-attack} we demonstrate that target-set coverage
attacks are feasible for practical BF parameters. We do so by simulating the
attack when~$H$ is a random function (i.e., for each distinct input we choose
$k$ integers from $[m]$ at random) for typical choices of $k$, $m$, and~$n$.
%
\todo{CP}{Add simulation to appendix.}

%\todo{DS (lead)}{Double check that Gerbet \etal don't suggest anything like this
%attack. If they do it's not a big deal; we just need to ensure, to the best of
%our ability, that we give credit where credit is due.}

The key to pollution attacks and target-set coverage attacks is that the
adversary can compute the representation of the set on its own. In the remainder
of this section, we examine ways of enhancing the basic BF structure so that it
avoids this pitfall.

\subsection{Salted BFs in the (im)mutable setting}
%
Here we consider the correctness of Bloom filters when the hashed input is
prepended with a salt.
%
Fix $H:\bits^*\to[m]^k$, $n,\lambda\geq0$, $\ell = kn$, and let
$\Pi = \SBF[H,\ell,n,\lambda] = (\Rep^H, \Qry^H, \Up^H)$ as defined above.

In the mutable setting, where the adversary is allowed to make $\UPO$ queries,
we can perform an $\errep$ attack against~$\Pi$ as follows. First, the adversary
calls $\REPO(\emptyset)$, receiving an empty filter and the salt. Now that the
adversary has the salt, it performs the exact same pollution attack as in the
unsalted case, with any evaluations of $H(x)$ replaced with evaluations of
$H(\salt \cat x)$. After a pollution set is found that sets many bits to 1, the
adversary calls $\UPO$ repeatedly to insert these elements into the filter. This
attack succeeds whenever the original pollution attack succeeds against an
unsalted filter.

%

The attack succeeds because the adversary can search for false positives on its
own as soon as it learns the salt. An adversary in the real world may not be
able to perform this exact attack, since even in the streaming setting it is
possible that the salt is not immediately revealed to the adversary. However, as
soon as the adversary does learn the salt, it can immediately launch a pollution
attack against the filter, without having to make any queries directly to the
filter. Just as in the immutable setting the adversary can exploit its knowledge
of the hash functions to find false positives without needing to make queries,
in the mutable and public-representation setting the adversary can identically
exploit its knowledge of the hash functions \textit{and salt} to find false
positives without needing to make queries.

\ignore{
The security of this structure depends upon how it is used.
%
\todo{DC (lead)}{As concisely as you can, articulate the \errep\ attack against~$\Pi$.
Remember that the adversarial model (i.e., the security experiment) is supposed
to reflect how the primitive is supposed to be used. So when giving attacks, try
to make it clear what the attack is. You should answer the following questions:
What is the sequence of queries made by the adversary?
How efficient is the attack?
Is the attack devastating? Is it a real attack, or is it more theoretical?
What about the scheme and setting make it possible?
%
Note that I've left your text in a ignore\{\} so that you can lift from it as
needed.
}
The use of a salt without a private key in the \errep\ setting is
insufficient to defeat [the attacka above]. In this setting, the adversary need only
make its $\REPO$ query for $\setT$ in advance, at which point it will receive
both the representation $\pub$ and the salt $\salt$ used to construct it. Using
this known salt, the adversary is still able to simulate $\REPO$ for arbitrary
singleton representations. The previous attack therefore still works with the
same (minimal) number of $\QRYO$ calls at the very end of the experiment, after
it has determined $\setR$ using offline computations.
\cpnote{I don't think this is true, since each $\ROPO$ query returns a filter
with a different, independently generated salt.}

The opposite of this, using a private key without a salt, does weaken the attack
somewhat. Even with public representations, the adversary cannot locally
simulate $\REPO$ without guessing the private key. However, they can still
outperform random $\QRYO$ calls by making $\REPO$ queries for singleton elements
without fixing any $\setT$ in advance. After selecting a random set $\col$ of
size $q_R-1$, the adversary performs offline computations to find $\setT$,
$\setR \subseteq \col$ such that the elements of $\setR$ are false positives for
the representation of $\setT$ (which can be computed from the representations of
the singleton subsets of $\setT$). The adversary wins if there is a partition
where $\setR$ produces at least $r$ errors on $\REPO(\setT)$.
\cpnote{This might be the case, but I don't think it's worth spending too much
time on. We're going to have other reasons for needing to add salt even when
there's a key.}

Using a salted Bloom filter in the private representation setting, however, does
provide some security. At the time a representation is created, the structure
chooses a salt $\salt$ which it will use for all further queries and updates. In
order for maximum security to be guaranteed, we must ensure that the
representation, and in particular the salt, is kept secret from the adversary.
We define this structure $\SBF[H,k,m,n,\lambda]$ as the Bloom filter structure
that uses $H(s) = (h_1(s),\ldots,h_k(s))$ for hashing inputs to $k$ values in
$[m]$. Furthermore, each call of $\Rep$ first involves picking a salt $\salt$
from the salt space $\bits^\lambda$, and all hashes made to insert or query for
an element $x$ are determined using $H(x \Vert \salt)$. Finally, the parameter
$n$ means that any attempts to represent sets with more than $n$ elements fail.
\todo{DC lead}{Specify what exactly is being analyzed.  What are the updates?}
}

Without this exploitation of mutability, and in particular the ability to insert
elements even after the salt has been seen, the above attack fails. Indeed, when
we restrict ourselves to the immutable setting, we can prove the following.
%
\begin{theorem}[Immutable \errep\ security of salted BFs]\label{thm:sbf-errep-immutable}
Let $p$ be the standard (non-adaptive) false positive probability for a Bloom
filter with the chosen parameters. For all integers $q_R, q_T, q_H, r, t \geq 0$
and for $q = q_T + q_H$, if $r > pq$, then it holds that
  \begin{equation*}
    \begin{aligned}
            \Adv{\errep}_{\Pi,\delta,r}(t,\,&q_R,q_T,0,q_H) \leq \\
        & q_R \cdot \left[\frac{q_H}{2^\lambda} +
        \left(\frac{pq}{r}\right)^re^{r-pq}\right] \,,
    \end{aligned}
  \end{equation*}
  where $H$ is modeled as a random oracle.  %
\end{theorem}
We consider only the case of $r > pq$ because $pq$ is the expected number of
false positives obtained by an adversary that simply uses its knowledge of the
salt (after the representation is created) to guess as many random elements as
possible. Because this simple adversary can get $pq$ successes on average, we
can only hope to provide good security bounds against arbitrary adversaries in
the case that $r > pq$.

This bound can be broken down into three main components. The external $q_R$
term means that the security guarantee will be weak in the case that the
adversary is able to view a large number of representations. The $q_H/2^\lambda$
term corresponds to the probability of the adversary guessing the salt before
the representation is constructed, but this will be negligibleas long as
$\lambda$ is chosen to be sufficiently large (say, $\lambda=128$). The final,
messier term comes from applying a Chernoff bound to the non-adaptive
adversary's probability of succeeding in the experiment given $q = q_H+q_T$
guesses.

By way of clarifying the performance of our bound, we have plotted the last
component for various parameters of interest. Let
%
\begin{equation}
  \zeta_{k,m,n}(q,r) = \left(\frac{pq}{r}\right)^re^{r-pq}
\end{equation}
%
and refer to Figure~\ref{fig:bf-bound}. This shows values
of~$\zeta_{k,m,n}(q,r)$ for varying~$m$ (filter length in kilobytes). What this
plot shows that, for a given error capacity~$r$, once a certain filter-length
threshold is reached, the $\zeta$ value decreases quite quickly. Moreover, the
rate at which~$\zeta$ decreases scales quite nicely with the error capacity. For
example, if one is willing to tolerate up to~$r=10$ false positives when for a
single filter (i.e., $q_R=1$) representing $n=100$ elements, then picking a
filter length of $3$ kilobytes is sufficient to ensure that observing~$10$ false
positives occurs with probability less than $2^{-17}$, even when the adversary
can make~$2^{64}$ RO queries.


\begin{figure}
  \hspace*{-10pt}
  \includegraphics{fig/bf-bound}
  \vspace{-24pt}
  \caption{
    The value of $\zeta_{k,m,n}(q,r)$ for $q=2^{64}$, $k=16$, $n=100$, varying
    values of~$r$ (one line per $r$-value) and filter length~$m$ (the x-axis).
    Note the log-2 scale on the y-axis.
  }
  \label{fig:bf-bound}
\end{figure}

\begin{proof}[Proof of Theorem~\ref{thm:sbf-errep-immutable}]
  \input{proof/sbf-errep-immutable}
\end{proof}


Recall that the attack against mutable salted filters exploited the fact that
the adversary learned the salt as soon as the filter was created, and that from
this it could compute the hash function on its own. Even if the filter is
mutable, we can prevent this attack from working as long as we require that the
filter under attack be kept secret from adversaries. In fact, we can attain the
following \erreps\ bound.

\begin{theorem}[\erreps\ security of salted BFs]\label{thm:sbf-erreps}
  For every $q_R, q_T, q_U, q_H, t, r\geq 0$, it holds that
  \begin{eqnarray*}
    \begin{aligned}
      \Adv{\erreps}_{\Pi,\delta,r}(t,q_R, q_T, q_U, q_H) &\leq \\
          \text{some cool bound} \,,
    \end{aligned}
\end{eqnarray*}
where $H$ is modeled as a random oracle
\end{theorem}

\todo{DC (lead)}{Turn this into a short summary of what's different from
Theorem~\ref{thm:sbf-errep-immutable}. In an earlier iteration this was the first result
in the paper, hence the length. But now it's the second result.}
%
The main idea behind the proof is to remove the adversary's
adaptivity a step at a time. We isolate the possibility of the adversary
guessing the salt, which would allow it to mount its own offline attack on the
filter without relying on the $\QRYO$ oracle. If the adversary does not guess
the salt, the outputs of the $\REPO$, $\QRYO$, and $\UPO$ oracles are
unpredictable to the adversary, producing uniformly randomly distributed bits to
set (for $\REPO$ and $\UPO$) or to check (for $\QRYO$). Under the assumption
that the adversary does not predict the salt, queries made to distinct elements
are independent of each other. The only remaining issue is that the adversary
can potentially gain an advantage by testing whether some object $x$ is a false
positive for the filter, and then updating the filter to include $x$ only if the
test query returned `false'.
%
An analysis shows that this is now (once imperfect
pseudorandom functions and salt collisions have been dealt with \cpnote{This
doesn't quite make sense ... there's no PRF in~$\Pi$})
%
the only way for the adversary to gain an advantage over making queries to an
immutable Bloom filter. Because this adaptive strategy introduces tricky
conditional possibilities, we cannot compute an exact value for the adversary's
advantage.  Instead, we move to an alternate scenario where each $\QRYO$ also
produces a free update and every $\UPO$ first performs a free query. This makes
$\QRYO$ and $\UPO$ calls indistinguishable, so that the adversary is effectively
making a series of independent random queries that each have a chance to
increment the error counter. Because the number of 1s in the filter can only
increase, the probability of a false positive from any one of these queries is
bounded above by the probability of a false positive on the final
maximally-sized filter, a probability which is given by the Kirsch and
Mitzenmacher bound.

\cpnote{I muted a ``In the ROM, salted hashing is almost as good as distinct
random functions'' lemma that appeared. As stated, I don't think it cleanly
isolates the part of the proof you're attempting to isolate. This is the
$\game_0$ to $\game_1$ transition in Theorem~\ref{thm:sbf-errep-immutable}. I think it's
better to leave this argument in-line in the proof.}
\ignore{
\begin{lemma}[In the ROM, salted hashing is almost as good as distinct random
  functions in \errep1]\label{lemma:salttorand}
  %
  Let $\struct = (\Rep, \Qry, \Up)$ be a data structure with key space
  $\{\emptystr\}$ and salt space $\bits^\lambda$, and let $\struct'$ be the same
  structure using true random functions in place of salted hash functions. For
  every $t, q_R, q_T, q_U, q_H, r \geq 0$, it holds that
  \[
    \Adv{\errep1}_{\struct,r}(t, q_R, q_T, q_U, q_H) \leq \frac{q_H}{2^\lambda} + \Adv{\errep1}_{\struct',r}(t, q_R, q_T, q_U, q_H)
  \]
\end{lemma}

\begin{proof}
Let $\game_0$ be the standard $\errep1$ game for the structure $\struct$, and
let $\game_1$ be the same game for $\struct'$. There exists an adversary $\advB$
such that $\Prob{\game_0(\advA) = 1} \le \Prob{\game_1(\advB) = 1} + q_H/2^\lambda$.
This adversary initializes an empty table $R$ and simulates $\advA$. When a
query $w$ is sent to $\HASHO$, $\advB$ returns $R[w]$ if this entry in the table
is defined. Otherwise, if $w = \langle\salt, x\rangle$ for some
$\salt \in \bits^\lambda$ and $x \in \bits^*$, forward $(\salt, x)$ to $\HASHO$,
store the result in $R[w]$, and return this value. Finally, if $R[w]$ is not
defined and $w$ is not of this form, sample $r$ uniformly from the range of the
hash function, store the result in $R[w]$ and return that result. Queries to all
other oracles are simply forwarded to $\advB$'s oracle. Assuming the output of
the hash function is uniformly distributed, this simulation is perfect unless
$\advA$ guesses the salt correctly, which happens with probability
$q_H/2^\lambda$.
\end{proof}
}

\begin{proof}[Proof of Theorem~\ref{thm:sbf-erreps}]
  \input{proof/sbf-erreps}
\end{proof}

\subsection{Keyed BFs}

Salted BFs are secure in the immutable setting \emph{or} the private
representation setting, but not both. Our argument for the \erreps\ security of
salted Bloom filters is made possible by virtue of the structure under attack
not being revealed to the adversary. While this is realistic in many settings,
it may be desirable for the Bloom filter to be public \emph{and} updatable.
%
Here we show that building a Bloom filter from a PRF suffices for security in
this setting.
%
So far our bounds have lost a factor of~$q_R$ in order to move from the \errep1\
to the \errep\ setting; as a bonus, here we show that it is possible to do
better.
%
Let $F:\keys\by\bits^*\to[m]^k$ be a function and fix
integers~$\ell,n,\lambda\geq0$.
%
Let $\Pi = \KBF[F,\ell,n,\lambda] = (\Rep^F, \Qry^F, \Up^H)$ as defined in
Figure~\ref{fig:bf-def}.

\begin{theorem}[\errep\ security of keyed BFs]\label{thm:bf-key-bound}
  For integers $q_R, q_T, q_H, r, t \geq 0$ it holds that.
  \begin{equation*}
    \begin{aligned}
      \Adv{\errep}_{\Pi,\delta,r}(t, q_R,q_T,q_U,q_H) &\leq \\
        \Adv{\prf}_{F}(\cdots) + \text{some cool bound} \,.
    \end{aligned}
  \end{equation*}
\end{theorem}
\begin{proof}
  \input{proof/kbf-errep}
\end{proof}

\todo{DC}{Add discussion of how the $\REVO$ oracle rules out the security of
keyed, unsalted Bloom filters. Be sure to mention that this was something
considered by Gerbet \etal~\cite{gerbet2015power}.}