\begin{figure}
  \twoColsNoDivide{0.22}
  {
    \underline{$\Rep^R_K(\col)$}\\[2pt]
      $\salt \getsr \bits^\lambda$;
      $\pub \gets \langle 0^m, \salt, 0\rangle$\\
      for $x \in \col$ do \\
        $\tab \pub \gets \Up^R_K(\pub, \qry_x)$\\
        $\tab$if $\pub = \bot$ then return $\bot$\\
      return $\pub$
  }
  {
    \underline{$\Qry^R_K(\langle M, \salt, c \rangle,\qry_x)$}\\[2pt]
      $X \gets \bmap_m(R_K(\salt \cat x))$\\
      return $M \AND X = X$
    \\[6pt]
    \underline{$\Up^R_K(\langle M, \salt, c \rangle,\qry_x)$}\\[2pt]
      if $c \geq n$ then return $\bot$\\
      $M \gets M \vee \bmap_m(R_K(\salt \cat x))$\\
      return $\langle M, \salt, c+1 \rangle$
  }
  \caption{The keyless structure $\bloom[R,n,\lambda]$ given by
  $(\Rep^R,\Qry^R,\Up^R)$ is used to define Bloom filter variants. The
  parameters are a function $R: \keys\by\bits^* \to [m]^k$ and integers $n,
  \lambda \geq0$. A concrete scheme is given by a particular choice of
  parameters.  The function~$\bmap_m$ is defined in
  Section~\ref{sec:prelims}.
  }
  \label{fig:bf-def}
\end{figure}

\begin{figure}
  \twoColsNoDivide{0.22}
  {
    \underline{$\Rep^R_K(\col)$}\\[2pt]
      $\salt \getsr \bits^\lambda$;
      $\pub \gets \langle 0^m, \salt\rangle$\\
      for $x \in \col$ do\\
        $\tab \pub \gets \Up^R_K(\pub,\qry_x)$\\
        $\tab$if $\pub = \bot$ then return $\bot$\\
      return $\pub$
  }
  {
    \underline{$\Qry^R_K(\langle M, \salt \rangle,\qry_x)$}\\[2pt]
      $X \gets \bmap_m(R_K(\salt \cat x))$\\
      return $M \AND X = X$
    \\[6pt]
    \underline{$\Up^R_K(\langle M, \salt \rangle,\qry_x)$}\\[2pt]
      if $\hw(M) > \ell$ then return $\bot$\\
      return $\langle M \vee \bmap_m(R_K(\salt \cat x)), \salt \rangle$
  }
  \caption{A slightly modified structure $\bloom_\mathrm{ft}[R,\ell,\lambda]$ given by
  $(\Rep^R,\Qry^R,\Up^R)$ which produces Bloom filter variants that use a different notion of fullness. The
  parameters are a function $R: \keys\by\bits^* \to [m]^k$ and integers $\ell,
  \lambda \geq0$. A concrete scheme is given by a particular choice of
  parameters.  Functions~$\hw$ and~$\bmap_m$ are defined in
  Section~\ref{sec:prelims}.
  }
  \label{fig:bft-def}
\end{figure}


\medskip
We specify three Bloom filter variants using the keyed structure
$\bloom[R,\ell,n,\lambda] = (\Rep^R,\Qry^R,\Up^R)$ specified in
Figure~\ref{fig:bf-def}.
%
The construction has four paraemters: a function~$R:\keys\by\bits^*\to[m]^k$,
\emph{set threshold} $n\geq0$, and the \emph{salt length}~$\lambda\geq0$.
%
Let $H:\bits^*\to[m]^k$ be a hash function and let $\ell, n, \lambda\geq0$ be
integers.
%
The standard Bloom filter is the structure $\BF[H,n,\lambda] =
\bloom[\id^H,n,0]$, which we will term the \emph{basic} Bloom filter. It
has no key (the key sapce of $\id^H$ is $\{\emptystr\}$, see
Section~\ref{sec:prelims}) and does not use a salt.
%
The \emph{salted} Bloom filter $\SBF[H,n,\lambda] =
\bloom[\id^H,n,\lambda]$ is the same except that it allows a nonempty salt.
%
We also consider a salted variant that uses a PRF instead of a hash
function. The \emph{keyed} Bloom filter $\KBF[F,n,\lambda]$ is the
structure $\bloom[F,n,\lambda]$, where $F:\keys\by\bits^*\to[m]^k$ is a
PRF.
%
Note that the basic and salted BFs have key spaces $\{\emptystr\}$ and the keyed
BF has key space~$\keys$.

In this section, we will show that the basic Bloom filter construction
$\BF[H,n]$ is flawed, allowing the adversary to make an offline attack that
has a high probability of success while using a minimal number of queries. In
the immutable setting, where the adversary is constrained to never use the
$\UPO$ oracle, i.e. $q_U = 0$, it suffices to use the $\SBF$ construction in
order to provide a good security guarantee in either the public-representation
or private-representation settings. However, in the case where we allow
$q_U > 0$ so that the adversary can make updates, we will find that $\SBF$ is
not secure in the public-representation setting. Instead, $\KBF$ must be used to
guarantee security.

Finally, we consider an alternate Bloom filter construction, as depicted in
Figure~\ref{fig:bft-def}, which uses a \emph{filter threshold} $\ell\geq0$ in
place of the set threshold. This means that, instead of bounding the number of
elements that can be inserted into the filter, we bound the number of bits in
the filter that can be set to 1. In the absence of an adaptive adversary this
construction performs very similarly to the standard Bloom filter, since for a
random input set the number of bits set to 1 can be predicted with a high degree
of accuracy from the number of elements in the underlying set. However, a filter
threshold allows us to obtain better bounds against adaptive adversaries and has
the additional advantage of not requiring a separate counter to keep track of
the number of elements in the filter. Each of the above special cases can be
extended to the filter-threshold construction in the natural way, though we only
consider the unkeyed and salted construction $\SBF_\mathrm{ft}$ to provide an example
of the tighter error bounds this alternate construction can provide.

In the non-adaptive setting, the false positive rate for a Bloom filter of $m$
bits using $k$ hash functions and storing $n$ items can be closely approximated
as $(1-e^{-kn/m})^k + O(1/m)$.~\cite{kirsch2006less} Over the course of $q_T$
random evaluations of $\Qry$, we would then expect about
$q_T((1-e^{-kn/m})^k + O(1/m))$ false positives to occur. Our goal is to
minimize the probability that even an adaptive adversary can perform
significantly better than this lower bound.

\heading{Error function for set-mempership queries}
%
Throughout this section we will use the error function $\delta:\bits^2\to\R$
defined as
\begin{equation*}
  \delta(a, b) =
  \begin{cases}
    0 & \text{if}\ a=b \\
    1 & \text{otherwise.}
  \end{cases}
\end{equation*}

\subsection{Insecurity of unsalted BFs}
Fix a hash function $H:\bits^*\to[m]^k$ and integer $n\geq0$ and
let $\Pi = \BF[H,n] = (\Rep^H, \Qry^H, \Up^H)$.
%
Suppose the adversary is interacting with a system representing a dataset
with~$\Pi$ and that it is able to choose some fraction of the input data.
For example, some web spiders use Bloom filters to store the set of webpages
which have already been visited during a crawl. Suppose the adversary controls
at least one such webpage and wishes to deny the spider access to a different
webpage, the `target webpage'. The adversary can choose the links present on its
own webpage, which will cause the spider to visit the chosen webpages and set
the corresponding bits of its Bloom filter to 1. If those links are chosen in
such a way that they produce a false positive for the target webpage, the spider
will then erroneously believe it has already visited the target webpage. The
target webpage will therefore never be visited during the spider's crawl.

\heading{Pollution attacks}
%
The goal of the attacks pointed out by Gerbet \etal~~\cite{gerbet2015power} is
to pollute the filter such that the ``average'' set-membership query yields a
false positive with high probability; to do so, the attacker chooses a set of
inputs that maximize the number of 1s in the filter. This strategy is especially
effective when the structure of the hash function is known to the adversary. In
particular, if a secretly-keyed cryptographically-secure function is not used,
the adversary can compute the hash function on its own in order to determine
which choices will set the maximum number of bits to 1, or which choices will
set certain target bits to 1 in order to cause specific false positives. They
show that with some reasonable parameter choices, the adversary can double the
false positive rate if they control a third of the inputs to the filter.
%

Gerbet \etal discuss multiple ways to mitigate pollution attacks, including
using alternate data structures besides Bloom filters or choosing the parameters
of the filter pesimistically, so that even if a pollution attack occurs, the
false positive rate is kept below some threshold of acceptability. Both of these
possibilities are potentially viable, but can significantly increase the amount
of memory required to store the data structure. Since Bloom filters are designed
to store large amounts of data compactly, these solutions may be unnaceptable in
practice. The authors also discuss the possibility of using a secretly-keyed
hash function. Since they assume that the filter itself is kept entirely
private, with no potential for long-term leakage or other phenomena modeled by
our $\REVO$ oracle, this does not fall prey to the attacks against keyed but
unsalted filters that occur in our model. In this paper we consider the
possibility that the structure may not be secret, either in the sense that it
may eventually be recovered (in the private-representation setting) or that it
is publicly available to potential adversaries (in the public-representation
setting). Simply using a MAC with a long-term secret key does not suffice to
secure a Bloom filter in these scenarios.

\heading{Target-set coverage attacks}
%
Of course, exhibiting a high false positive rate is not the only way a Bloom
filter might fail to be correct. In particular, it would be undesirable if the
filter were consistently incorrect on a \emph{particular set of inputs}. Rather
than pollute the filter, the adversary's goal might be to craft a set of
legitimate looking inputs that cover some disjoint target set of inputs.
%
This type of attack is nicely captured by our adversarial model.
%
In a \emph{target-set coverage attack}, the adversary is given a small target set
$\setT\subseteq\bits^*$ and searches for a cover set $\setR\subseteq\bits^*$
such that $\Qry^H(\Rep^H(\setR),x)=1$ for each $x\in\setT$.
%
Once a suitable cover set is found, the adversary queries $\Rep(\setR)$. Then
for each $x\in\setT$, it asks $\Qry(x)$, achieving a score of $r = |\setT|$.

This \erreps1 attack succeeds with probability~$1$ assuming a covering set can
be found.  If $|\setT| \leq |\setR|$, then such a set exists; but finding it may be
computationally infeasible, depending on the size of the cover set, the size of
the target set, and the parameters of the Bloom filter.
%
In Appendix~\ref{app:unsalted-attack} we demonstrate that target-set coverage
attacks are feasible for practical BF parameters. We do so by simulating the
attack when~$H$ is a random function (i.e., for each distinct input we choose
$k$ integers from $[m]$ at random) for typical choices of $k$, $m$, and~$n$.
%
\todo{CP}{Add simulation to appendix.}

%\todo{DS (lead)}{Double check that Gerbet \etal don't suggest anything like this
%attack. If they do it's not a big deal; we just need to ensure, to the best of
%our ability, that we give credit where credit is due.}

The key to pollution attacks and target-set coverage attacks is that the
adversary can compute the representation of the set on its own. In the remainder
of this section, we examine ways of enhancing the basic BF structure so that it
avoids this pitfall.

\subsection{Salted BFs in the (im)mutable setting}
%
Here we consider the correctness of Bloom filters when the hashed input is
prepended with a salt.
%
Fix $H:\bits^*\to[m]^k$ and $n,\lambda\geq0$ and let
$\Pi = \SBF[H,n,\lambda] = (\Rep^H, \Qry^H, \Up^H)$ as defined above.

In the mutable setting, where the adversary is allowed to make $\UPO$ queries,
we can perform an $\errep$ attack against~$\Pi$ as follows. First, the adversary
calls $\REPO(\emptyset)$, receiving an empty filter and the salt. Now that the
adversary has the salt, it performs the exact same pollution attack as in the
unsalted case, with any evaluations of $H(x)$ replaced with evaluations of
$H(\salt \cat x)$. After a pollution set is found that sets many bits to 1, the
adversary calls $\UPO$ repeatedly to insert these elements into the filter. This
attack succeeds whenever the original pollution attack succeeds against an
unsalted filter.

%

The attack succeeds because the adversary can search for false positives on its
own as soon as it learns the salt. An adversary in the real world may not be
able to perform this exact attack, since even in the streaming setting it is
possible that the salt is not immediately revealed to the adversary. However, as
soon as the adversary does learn the salt, it can immediately launch a pollution
attack against the filter, without having to make any queries directly to the
filter. Just as in the immutable setting the adversary can exploit its knowledge
of the hash functions to find false positives without needing to make queries,
in the mutable and public-representation setting the adversary can identically
exploit its knowledge of the hash functions \textit{and salt} to find false
positives without needing to make queries.

\ignore{
The security of this structure depends upon how it is used.
%
\todo{DC (lead)}{As concisely as you can, articulate the \errep\ attack against~$\Pi$.
Remember that the adversarial model (i.e., the security experiment) is supposed
to reflect how the primitive is supposed to be used. So when giving attacks, try
to make it clear what the attack is. You should answer the following questions:
What is the sequence of queries made by the adversary?
How efficient is the attack?
Is the attack devastating? Is it a real attack, or is it more theoretical?
What about the scheme and setting make it possible?
%
Note that I've left your text in a ignore\{\} so that you can lift from it as
needed.
}
The use of a salt without a private key in the \errep\ setting is
insufficient to defeat [the attacka above]. In this setting, the adversary need only
make its $\REPO$ query for $\setT$ in advance, at which point it will receive
both the representation $\pub$ and the salt $\salt$ used to construct it. Using
this known salt, the adversary is still able to simulate $\REPO$ for arbitrary
singleton representations. The previous attack therefore still works with the
same (minimal) number of $\QRYO$ calls at the very end of the experiment, after
it has determined $\setR$ using offline computations.
\cpnote{I don't think this is true, since each $\ROPO$ query returns a filter
with a different, independently generated salt.}

The opposite of this, using a private key without a salt, does weaken the attack
somewhat. Even with public representations, the adversary cannot locally
simulate $\REPO$ without guessing the private key. However, they can still
outperform random $\QRYO$ calls by making $\REPO$ queries for singleton elements
without fixing any $\setT$ in advance. After selecting a random set $\col$ of
size $q_R-1$, the adversary performs offline computations to find $\setT$,
$\setR \subseteq \col$ such that the elements of $\setR$ are false positives for
the representation of $\setT$ (which can be computed from the representations of
the singleton subsets of $\setT$). The adversary wins if there is a partition
where $\setR$ produces at least $r$ errors on $\REPO(\setT)$.
\cpnote{This might be the case, but I don't think it's worth spending too much
time on. We're going to have other reasons for needing to add salt even when
there's a key.}

Using a salted Bloom filter in the private representation setting, however, does
provide some security. At the time a representation is created, the structure
chooses a salt $\salt$ which it will use for all further queries and updates. In
order for maximum security to be guaranteed, we must ensure that the
representation, and in particular the salt, is kept secret from the adversary.
We define this structure $\SBF[H,k,m,n,\lambda]$ as the Bloom filter structure
that uses $H(s) = (h_1(s),\ldots,h_k(s))$ for hashing inputs to $k$ values in
$[m]$. Furthermore, each call of $\Rep$ first involves picking a salt $\salt$
from the salt space $\bits^\lambda$, and all hashes made to insert or query for
an element $x$ are determined using $H(x \Vert \salt)$. Finally, the parameter
$n$ means that any attempts to represent sets with more than $n$ elements fail.
\todo{DC lead}{Specify what exactly is being analyzed.  What are the updates?}
}

Without this exploitation of mutability, and in particular the ability to insert
elements even after the salt has been seen, the above attack fails. Indeed, when
we restrict ourselves to the immutable setting, we can prove the following.
%
\begin{theorem}[Immutable \errep\ security of salted BFs]\label{thm:sbf-errep-immutable}
Let $p$ be the standard (non-adaptive) false positive probability for a Bloom
filter with the chosen parameters. For all integers $q_R, q_T, q_H, r, t \geq 0$
and for $q = q_T + q_H$, if $r > pq$, then it holds that
  \begin{equation*}
    \begin{aligned}
            \Adv{\errep}_{\Pi,\delta,r}(t,\,&q_R,q_T,0,q_H) \leq \\
        & q_R \cdot \left[\frac{q_H}{2^\lambda} +
        \left(\frac{pq}{r}\right)^re^{r-pq}\right] \,,
    \end{aligned}
  \end{equation*}
  where $H$ is modeled as a random oracle.  %
\end{theorem}
We consider only the case of $r > pq$ because $pq$ is the expected number of
false positives obtained by an adversary that simply uses its knowledge of the
salt (after the representation is created) to guess as many random elements as
possible. Because this simple adversary can get $pq$ successes on average, we
can only hope to provide good security bounds against arbitrary adversaries in
the case that $r > pq$.

This bound can be broken down into three main components. The external $q_R$
term means that the security guarantee will be weak in the case that the
adversary is able to view a large number of representations. The $q_H/2^\lambda$
term corresponds to the probability of the adversary guessing the salt before
the representation is constructed, but this will be negligibleas long as
$\lambda$ is chosen to be sufficiently large (say, $\lambda=128$). The final,
messier term comes from applying a Chernoff bound to the non-adaptive
adversary's probability of succeeding in the experiment given $q = q_H+q_T$
guesses.

By way of clarifying the performance of our bound, we have plotted the last
component for various parameters of interest. Let
%
\begin{equation}
  \zeta_{k,m,n}(q,r) = \left(\frac{pq}{r}\right)^re^{r-pq}
\end{equation}
%
and refer to Figure~\ref{fig:bf-bound}. This shows values
of~$\zeta_{k,m,n}(q,r)$ for varying~$m$ (filter length in kilobytes). What this
plot shows that, for a given error capacity~$r$, once a certain lower bound on
the filter size is reached, the $\zeta$ value decreases quite quickly. Moreover,
the rate at which~$\zeta$ decreases scales quite nicely with the error capacity.
For example, if one is willing to tolerate up to~$r=10$ false positives when for
a single filter (i.e., $q_R=1$) representing $n=100$ elements, then picking a
filter length of $3$ kilobytes is sufficient to ensure that observing~$10$ false
positives occurs with probability less than $2^{-17}$, even when the adversary
can make~$2^{64}$ RO queries.


\begin{figure}
  \hspace*{-10pt}
  \includegraphics{fig/bf-bound}
  \vspace{-24pt}
  \caption{
    The value of $\zeta_{k,m,n}(q,r)$ for $q=2^{64}$, $k=16$, $n=100$, varying
    values of~$r$ (one line per $r$-value) and filter length~$m$ (the x-axis).
    Note the log-2 scale on the y-axis.
  }
  \label{fig:bf-bound}
\end{figure}

\begin{proof}[Proof of Theorem~\ref{thm:sbf-errep-immutable}]
  \input{proof/sbf-errep-immutable}
\end{proof}


Recall that the attack against mutable salted filters exploited the fact that
the adversary learned the salt as soon as the filter was created, and that from
this it could compute the hash function on its own. Even if the filter is
mutable, we can prevent this attack from working as long as we require that the
filter under attack be kept secret from adversaries. In fact, we can attain the
following \erreps\ bound.

\begin{theorem}[\erreps\ security of salted BFs]\label{thm:sbf-erreps}
Let $p_*$ be the standard (non-adaptive) false positive probability for a Bloom
filter with the chosen parameters \emph{except} that the set threshold is
increased from $n$ to $n+r$. For all integers $q_R, q_T, q_H, r, t \geq 0$, if
$r > p_*q_T$, then it holds that
  \begin{eqnarray*}
    \begin{aligned}
      \Adv{\erreps}_{\Pi,\delta,r}(t,q_R, q_T, q_U, q_H) &\leq \\
          & q_R \cdot \left[
      \frac{q_H}{2^\lambda} +
      \left(\frac{p_*q_T}{r}\right)^re^{r-p_*q_T}\right]\,,
    \end{aligned}
\end{eqnarray*}
where $H$ is modeled as a random oracle
\end{theorem}

This proof follows a very similar structure to that of
Theorem~\ref{thm:sbf-errep-immutable}. The primary differences come from arguing
that without a `lucky' guess of the salt the adversary cannot use offline hash
queries to find false positives, and from having to show that the adversary's
access to $\UPO$ does not substantially change the security bound that can be
derived. The first of these is straightforward given the private-representation
setting, but the second requires investigating how much of an advantage the
$\UPO$ oracle can give in a pollution attack, and then moving to games where
this advantage is taken into account.

\begin{proof}[Proof of Theorem~\ref{thm:sbf-erreps}]
  \input{proof/sbf-erreps}
\end{proof}

\subsection{Keyed BFs}

Salted BFs are secure in the immutable setting \emph{or} the private
representation setting, but not both. Our argument for the \erreps\ security of
salted Bloom filters is made possible by virtue of the structure under attack
not being revealed to the adversary. While this is realistic in many settings,
it may be desirable for the Bloom filter to be public \emph{and} updatable.
%
Here we show that building a Bloom filter from a PRF suffices for security in
this setting.
%
Let $F:\keys\by\bits^*\to[m]^k$ be a function and fix
integers~$n,\lambda\geq0$.
%
Let $\Pi = \KBF[F,n,\lambda] = (\Rep^F, \Qry^F, \Up^F)$ as defined in
Figure~\ref{fig:bf-def}.

\begin{theorem}[\errep\ security of keyed BFs]\label{thm:bf-key-bound}
Let $p_*$ be the standard (non-adaptive) false positive probability for a Bloom
filter with the chosen parameters \emph{except} that the set threshold is
increased from $n$ to $n+r$.
For integers $q_R, q_T, q_H, r, t \geq 0$, if $r > p_*q_T$, it holds that
  \begin{equation*}
    \begin{aligned}
      \Adv{\errep}_{\Pi,\delta,r}(t, q_R,q_T,q_U,q_H) &\leq \\
        \Adv{\prf}_F(t,nq_R+q_T+q_U) & +
      \frac{q_R^2}{2^\lambda} +
      \left(\frac{p_*q_Rq_T}{r}\right)^re^{r-p_*q_Rq_T}
    \end{aligned}
  \end{equation*}
\end{theorem}

Though the bound is similar, and the underlying idea of showing oracle queries
are independent and thereby reducing to the non-adaptive case is still present,
the technicalities of this proof differ from the previous two. In particular,
since we are using a PRF, the initial parts of the proof deal with the adversary
potentially being able to break the PRF and with the possibility of the salts
repeating rather than with the adversary being able to guess the salt.

\begin{proof}
  \input{proof/kbf-errep}
\end{proof}

The fact that both a key and a salt are used in the $\KBF$ construction is
critical. In particular, without the per-representation randomness given by the
salt, we would not be able to argue that $\UPO$ and $\QRYO$ calls are
independent across representations. On the contrary, seeing the representation
of a singleton set $\{x\}$ would immediately allow the adversary to test whether
$x$ was a member in every other representation that had been constructed, simply
by testing whether every bit set to 1 in the representation of $\{x\}$ was also
set to 1 in other representations. Even in the \erreps\ game, using the $\REVO$
oracle on some representations leaks information about other representations,
and again we cannot use the argument that provides the above bound.

We note that Gerbet \etal~\cite{gerbet2015power} suggest using cryptographic
hash functions as one possibility for constructing secure filters, which is
equivalent in our terminology to using a keyed but unsalted filter. The
distinction is that Gerbet \etal assume that representations are kept private
indefinitely, an assumption similar to that underlying our \erreps\ game but
with the stronger restriction that the adversary has no equivalent of a $\REVO$
oracle. Without this assumption that representations are never leaked to the
adversary, however, we emphasize that merely using a long-term secret key
without a per-representation salt does not guarantee security.

\subsection{Thresholded BFs}

While the above proofs show security bounds for Bloom filters in certain
settings, the bounds may not be as tight as we would like for applications. The
extra factor of $q_R$ in the error bound, for example, may prevent a filter from
achieving good security in practice. We show that a stronger bound can be
achieved using the tweaked Bloom filter construction $\SBF_\mathrm{ft}$, showing
a better bound in the private-representation setting than we had for $\SBF$.
%
\begin{theorem}[\errep\ security of thresholded BFs]\label{thm:bf-thr-bound}
Let $p_\ell = ((\ell+k)/m)^k$. For integers $q_R, q_T, q_H, r, t \geq 0$ such
that $r > p_\ellq_T$, it holds that
  \begin{equation*}
    \begin{aligned}
      \Adv{\errep}_{\Pi,\delta,r}(t, q_R,q_T,q_U,q_H) &\leq \\
        & \frac{q_R(q_H+q_R)}{2^\lambda} + e^{r-p_\ell q_T}\left(\frac{p_\ell q_T}{r}\right)^r.
    \end{aligned}
  \end{equation*}
\end{theorem}

The distinction between this proof and the proofs for the standard Bloom filter
construction lies in the fact that pollution attacks cannot set more than
$\ell+k$ bits of the filter to 1, regardless of how the attack is conducted.
We therefore assume that the adversary will always be able to produce such a
maximally full filter, and then use a standard binomial-distribution-based bound
to place a limit on the adversarial advantage even in this worst-case scenario.

\begin{proof}
  \input{proof/sbf-erreps-th}
\end{proof}