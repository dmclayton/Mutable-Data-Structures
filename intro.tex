Data structures are fundamental to essentially all areas of computer science.
The traditional approach to analyzing the correctness of a data structure is to
assume that all inputs, and all queries, are independent of any internal
randomness used to construct it.  But as highlighted by Naor and
Yogev (CRYPTO '15~\cite{naor2015bloom}), there are important use-cases in which the inputs
and queries may be chosen \emph{adversarially} and \emph{adaptively}, based on
partial information and prior observations about the data structure. Attacks of
this sort can be used to disrupt or reduce the availability of real systems
\cite{crosby2003denial,gerbet2015power,lipton1993clocked}.

Naor and Yogev (NY) formalized a notion of adversarial correctness for
Bloom-filter-like structures. Recall that a Bloom filter provides a compact
representation, $\pub$, of a set~$\col$. The representation is a length~$m$
bit-array (initally all zeros), and elements $x \in \col$ are added to it by
computing hash values $h_1(x),h_2(x),\ldots,h_k(x)\in [m]$, then setting the
indicated array positions to~$1$.  A Bloom filter supports set membership
queries, i.e., ``is $x\in\col$?'', by hashing~$x$ and responding positively
iff all of the indicated positions hold a 1-bit.  When $h_1,\ldots,h_k$ are
modeled as random functions, and~$\col$ is independent of these, classical
results relate $|\col|,m,k$ to the probability of false-positive query
responses~\cite{broder2004network,kirsch2006less}.
%
NY revisited these results from a security perspective, by
formalizing an attack model in which the adversary specifies a
(fixed) set~$\col$ that may
depend on the hash functions, and is then allowed to adaptively query the
(immutable) representation~$\pub$ in an effort to induce errors.

This work expands upon NY in several, practically relevant ways.  To begin, our
attack model allows the adversary to adaptively \emph{update} the
collection~$\col$, thereby capturing settings in which the target data may
change over time, e.g., streaming data applications.  Correspondingly, we
consider data structures that natively support \emph{mutable} representations.
Concrete examples of these include the counting filter~\cite{xxx}, count-min
sketch~\cite{xxx}, the cuckoo filter~\cite{xxx}, \todo{DC}{Add references and
add any other data structuers you feel should be named here.}
%
Next, while the Bloom filter was designed to represent
data collections~$\col$ that are sets, streaming data is
better modeled as a multiset.  Natural questions about multisets
extend beyond set-membership; for example, an important question in practice is
\emph{how many times does~$x$ appear in~$\col$?}  

Thus, our syntatic definition of data structures admits both
mutability and rich query spaces.
Formally, a data structure as a triple of algorithms $(\Rep, \Qry, \Up)$ denoting
the \emph{representation}, \emph{query-evaluation}, and \emph{Update} algorithms, respectively.
Associated to the data structure is a set of supported
queries~$\mathcal{Q}$, which are functions~$\qry$ over data objects,
and a set~$\mathcal{U}$ of allowed update functions.
For reasons we will elucidate in a moment, all three algorithms take a
key~$\ky$ as input, and both~$\Rep$ and~$\Qry$ may be randomized.


The combination of mutability and rich query spaces has significant
implications for security.  Consider the count-min
sketch structure~\cite{xxx}, which compactly (and approximately)
represents an updatable multiset~$\col$.  
Loosely, the representation of~$\col$ is a two-dimensional array
of counters. To add an instance of~$x$, the representation is
updated by hashing~$x$ to identify particular counters, and then
incrementing these.  An instance of~$x$ is removed
by hashing and decrementing the counters.  
The frequency of~$x$ is determined by taking
the minmum value~$v$ over the counters associated to it. (Counters are
typically floored at 0.)  Now, if one
restricts to set-membership queries ---~is $v>0$?~-- there is the
potential for both false-positive \emph{and} false-negative
responses.  In particular, if the representation is updated by
``removing'' an element~$y$ that does not appear in the
underlying~$\col$, one or more of the counters associated to~$x$ may
be decremented.  

Even though it is two-sided, the notion of error with respect to set-membership
queries is intuitive, even if one wants to associate different
fixed costs to false-positives and false negatives.  For frequency
queries, it is far less obvious.   One could define frequency-estimate
error in an absolute sense, i.e., the data structure errs if its
response is not exactly correct.  But even in the non-adaptive
setting, traditional analyses guarantee only that the response will be
\emph{close} to the exact frequency, with some probability that is close
to one.  Thus, our security definitions are parameterized by a
error-cost function~$\delta$: if the correct response to a query is~$a$ and
the data structure responds with~$a'$, the cost of the error is
$\delta(a,a') \geq 0$.  

They are also parameterized by an total-cost threshold, and
the adversary is considered to ``win'' if the total cost of the errors it induces
is greater than this value.  As we will see, even calculating the
total cost is not straightforward.  In particular, determining whether
or not the cost of a given error should be carried across (adaptive,
adversarial) updates to~$\col$ and its representation.

To summarize, our high-level contributions are: formal syntax for
mutable data structures, and two notions of adversarial 
correctness for these.  Our notions capture settings in which representations
are made public, or kept private, respectively.

We exercise our syntax and notions by
analyzing three important, real-world data structures: Bloom
filters~\cite{xxx}, counting filters~\cite{xxx}, and count-min
sketches~\cite{xxx}. 
In addition to the basic version of these, we
explore variations that allow for ``salted'' representations (i.e.,
per-representation randomness), secret keys (so that the mapping
from~$\col$ to representation is unpredictable, even if the
representation of one or more closely related~$\col'$ are known), or both.

\heading{Security findings.}
%\input{fig-results-overview}

\tsnote{Stuff to do, typed up quickly during our Tuesday afternoon meeting...}
\begin{itemize}
\item $n$-capped does not imply $\ell$-thresholded for any
  particular~$\ell$ except in the non-adaptive setting
\item \dctodo{Summary of Results!  Break out into items, here.}
\item \dctodo{A paragraph that summarizes the summary of results --
    the elevator pitch}
\item \dctodo{Add Section/sub-section summary blurbs to intro, to
    shape final intro story}
\item \anytodo{We need to tie our analytical settings to reality --
    what do salts imply in practice?  Keys?}
\item \dctodo{How do representation sizes compare to prior work?  What
    can we say about them in a concrete sense (not compared to prior
    work)?}
\item Make sure to hit the online vs. offline query issue
\item For parallel structure and completeness, there are a bunch of
  things we could consider, but don't.  Why?  Any reasons we can give
  for skipped cases (other than ``because it's hard'', and ``because
  it takes to much space'') will help convince reviewers that we
  aren't lazy
\item ...
\end{itemize}

\dcnote{Summaries follow:}
\begin{itemize}
  \item Overall pitch: We construct general definitions to capture the idea of a
  probabilistic data structure and define notions of what it means for these
  structures to be secure against an adversary attempting to force the
  structures to produce errors when queried. We show that three traditional data
  structures, the Bloom filter, the count-min sketch, and the counting filter,
  are insecure in their usual form. Any of these can be kept secure by keeping
  the representation private, adding a per-representation random salt to the
  hash functions, and introducing a simple `thresholding' procedure to ensure
  that the structures do not become too full. With Bloom filters, we can get
  away with not using thresholding, and even with only keeping a key
  for the hash functions secret rather than the entire filter, but the
  security bounds are weaker. If the filter is assumed to be immutable after
  construction, we can even get away with not keeping anything secret, though
  the security bound is \emph{much} weaker.
  \item Standard Bloom filters (4.1): With no salt or key there is no security
  in either sense.
  \item Salted Bloom filters (4.2): If the filters are immutable, we find a weak
  ($q_H$ features prominently) \errep\ bound. If the filters are mutable, we
  show an attack in the \errep\ setting and provide a decent bound for \erreps\
  security.
  \item Keyed Bloom filters (4.3): We get a decent bound for the \errep\
  setting.
  \item Salted, $\ell$-thresholded Bloom filters (4.4): We get a better
  \erreps\ bound than in the $n$-capped case.
  \item Count min-sketch (5.1-2): We show that \errep\ security is impossible
  regardless of which construction you use (key, threshold, etc.), but that
  \erreps\ security is achievable using a salt and $\ell$-thresholding.
  \item Counting filter (6.1-2): Same results as count min-sketch, with a
  slightly different security bound. This bound is given in terms of $\delta^+$
  and $\delta^-$, which describe the relative `badness' of false positives and
  false negatives. A large value of $\delta^-$ is more harmful than a large
  value of $\delta^+$, i.e. counting filters are better for avoiding false
  positives than false negatives. (Interestingly, the opposite is true in the
  non-adpative case.)
\end{itemize}
\tsnote{old stuff below here}

\ignore{ %possibly move elsewhere in the intro, or the opening to the
         %bloom filter section
Bloom filters are
ubiquitous in distributed computing, including web caches (e.g., Squid) and hash
tables (e.g., BigTable and Hadoop), resource and packet routing, and network
measurement. (We refer the reader to the
surveys~\cite{broder2004network,tarkoma2012theory} for a comprehensive list of
applications.) 
Bloom filters have also been modified and co-opted for security-critical
applications; perhaps unsurprisingly, things go wrong. Schnell
\etal~\cite{schnell2011novel} proposed using secretly-keyed Bloom filters in
order to enable privacy-preserving record linkage (PPRL) across data sets.  This
was deployed in medical-data applications in Australia, Brazil, Germany, and
Switzerland~\cite{niedermeyer2014cryptanalysis}. 
%As one exercise of our
%notions, we study their proposal in detail. % in Section~\ref{sec:bf-bigram}.
%
}


\heading{Data structures and their correctness.}
%
We formalize a data structure as a triple of algorithms $(\Rep, \Qry, \Up)$ denoting
the \emph{representation}, \emph{query-evaluation}, and \emph{Update} algorithms, respectively.
Associated to the data structure is a set of supported queries~$\mathcal{Q}$.
The representation algorithm is randomized, taking as input a
key~$\ky$ and a collection of data~$\col$, and returning a
representation~$\pub$ of~$\col$.  (To capture unkeyed data structures,
one sets $\ky=\varepsilon$.)
%
The deterministic query-evaluation algorithm~$\Qry$ uses~$\ky$ and $\pub$ in
order to respond to a requested query~$\qry \in \queries$ on~$\col$.
\textcolor{blue}{[[...]]}

For better efficiency, many data structures only approximately
represent the collection~$\col$. In this case, the query-evaluation
algorithm~$\Qry$ may err in its response to queries.  \oldstuff{Roughly
speaking,  our notion of adversarial correctness (\errep) captures how
difficult it is for an attacker (given $\pub$) to find~$r>0$ distinct queries on
which $\Qry$ returns an incorrect answer.}

For Bloom filters, the representation~$\pub$ includes a bit array~$M$ that
represents a set~$\col \subseteq \elts$ using hash functions
$h_1,\ldots,h_k$. The supported queries are the predicates
$\{\qry_x\}_{x\in\elts}$, where $\qry_x(\col)=1$ iff $x \in \col$. It is well
known that Bloom filters may have false positives, and their false-positive rate
for \emph{independently chosen} inputs and queries is well understood. (See
Appendix~\ref{sec:mitz}.) Our correctness notion quantitatively captures the
error rate even in the presence of an attacker that adaptively attempts to
induce errors. \textcolor{blue}{[[...]]}

We note that Naor and Yogev~\cite{naor2015bloom} were the first to formalize
adversarial correctness of Bloom filters and, indeed, their work
provided inspiration for this paper.  Our work significantly extends
theirs in several ways, as we will detail, shortly.  \textcolor{blue}{[[...]]}
% ss-rep
\if{0}{
  \anytodo{Several reviewers have made the same complaint : why these notions?
  In particular, are they interesting beyond an academic exercise?  We need to
  address this head-on.  One idea is to try to build something on top of these
  notions, but I really see that as a separate paper.  Unless we can build some
  \emph{well known} primitive... but I'm not sure what it would be, or how
  interesting.}
  %
  \cpnote{Alex Davidson's paper (ia.cr/2017/448) suggests that garbled Bloom
  filters (or some variation of them) can be used for private-set intersection. We
  could ask if privacy in our sense suffices for this application.
  But \ssrep is not the right notion since it requires a key, and \owrep is
  probably too weak. Davidson views GBFs as distributional virtual black-box
  obfuscators, which are stronger than \owrep-secure structures.}
  %
  \cpnote{To my thinking, these notions were originally devised from the
  perspective of what security properties do existing data structures admit. If
  our intention is to use these properties in order to achieve some higher-level
  goal, I don't think we have the right ones. Short of strengthening them, I think
  our best bet  is to \emph{own} our original perspective. To that end, the place
  we need the most motivation is \ssrep privacy of $\SKBF$, the PRF-based BF. See
  my comments in Section~\ref{sec:bf-prf} for two ways we've already thought of.}
}\fi

\heading{Constructions we analyze.}
%
We put our syntax and security notions to work in several case studies.
%
The brief description of Bloom filters given above was silent as to how the hash
functions $h_1, \ldots, h_k$ are chosen, and whether or not they are
public. In fact, these details have a significant effect on what notions of
security the resulting structure satisfies:
\begin{itemize}
  \item
    (Section~\ref{sec:bf}) If the hash functions are fixed and known to the
    attacker prior to the filter being constructed, the data structure offers
    neither correctness nor privacy for any practically interesting parameters.
    We show this by exhibiting explicit attacks and analyzing their performance.

  \item (Section~\ref{sec:bf-salt}) If \emph{salted} hash functions are used,
    and the adversary is given the salt only after the collection $\col$ is
    chosen, then %with modest changes to the parameters (i.e., the filter length and number of hashes), 
    the structure can achieve the same correctness guarantees in the adversarial setting as do Bloom filters in the traditional
    non-adversarial setting. 
    %(Our analysis here treats the hash functions as random oracles; the usual analysis treats them as ideal random functions.)
    We also show that this structure achieves our privacy notion of one-wayness.

  \item (Section~\ref{sec:bf-prf}) We explore a natural, keyed variant of a
    Bloom filter in which the hash functions are derived from a secretly keyed
    pseudorandom function. (This is similar to a construction proposed by Naor
    and Yogev~\cite{naor2015bloom}.) We show that this variant enjoys
    simulation-based privacy, as well as a tighter security bound for
    correctness than the salted Bloom filter.
\end{itemize}
%
\noindent
Our particular realization of the salted and secretly keyed Bloom filters
leverages results from Kirsch and Mitzenmacher~\cite{kirsch2006less} that allow
one to effectively implement $h_1,\ldots, h_k$ by making only two \emph{actual}
evaluations of an underlying hash function or PRF, respectively.
%
In addition to the comprehensive analysis of Bloom filters described above, we
also apply our definitions to:
\begin{itemize}
  \item (Section~\ref{sec:bf-bigram}) A keyed structure for privacy-preserving
    record linkage introduced by Schnell \etal~\cite{schnell2011novel}, and
    subsequently attacked by Niedermeyer
    \etal~\cite{niedermeyer2014cryptanalysis}. In our framework we are able to
    show precisely how their scheme breaks down.

  \item (Section~\ref{sec:dict}) A dictionary proposed by Charles
    and Chellapilla~\cite{charles2008bloomier2} that stores a set of~$n$
    key/value pairs, where the keys are arbitrary bitstrings and the values are
    of length at most~$m$, using just $O(mn)$ bits.
\end{itemize}

\heading{Future research directions.}
%
\ignore{
It would be interesting to extend our work to the case of \emph{mutable} data
structures. Specific examples to consider here are counting Bloom
filters~\cite{fan2000summary}, scalable Bloom
filters~\cite{almeida2007scalable}, count-min
sketches~\cite{cormode2005improved}, and hierarchical Bloom
filters~\cite{zhu2004hierarchical}, to name just a few in the extended Bloom
filter family.
}

% NOTE(all) Removed these citations: \cite{broder2004network,nojima2009cryptographically}
Our goal is to establish foundations for the security of  data
structures. But it would certainly be interesting to analyze high-level
protocols that use these data structures, e.g.
content-distribution networks~\cite{byers2002informed}, where many servers
propagate representations of their local cache to their neighbors. The Bloom
filter family alone has a wide range of practical applications, for example in
large database query processing~\cite{broder2004network}, routing algorithms for
peer-to-peer networks~\cite{reynolds2003efficient}, protocols for establishing
linkages between medical-record databases~\cite{schnell2011novel}, fair routing
of TCP packets~\cite{feng2001stochastic}, and Bitcoin wallet
synchronization~\cite{gervais2014privacy}.
%
Analyzing higher-level primitives or protocols will require establishing
appropriate syntax and security notions for those, too; hence we leave this for
future work.

%\heading{Related work.}
\input{related}
